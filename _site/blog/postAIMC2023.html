<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="robots" content="index,follow">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="A Music Informatics and Performance Technologies Lab based in the School of Media, Film and Music at the University of Sussex">
    
    <title>Post-AIMC 2023 Reflection - Emute Lab</title>


    <link rel="canonical" href="http://localhost:4000/blog/postAIMC2023">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/clean-blog.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Custom Fonts 
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Josefin+Sans&subset=latin,latin-ext' rel='stylesheet' type='text/css'>
    
-->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>

    <!-- Thor: exploring fonts -->
 <!--
    <link href='https://fonts.googleapis.com/css?family=Quicksand' rel='stylesheet' type='text/css'>
<link href='https://fonts.googleapis.com/css?family=Raleway' rel='stylesheet' type='text/css'>
<link href='https://fonts.googleapis.com/css?family=Muli' rel='stylesheet' type='text/css'>
<link href='https://fonts.googleapis.com/css?family=Questrial' rel='stylesheet' type='text/css'>
<link href='https://fonts.googleapis.com/css?family=Cantarell' rel='stylesheet' type='text/css'>
<link href='https://fonts.googleapis.com/css?family=Varela+Round' rel='stylesheet' type='text/css'>
<link href='https://fonts.googleapis.com/css?family=Molengo' rel='stylesheet' type='text/css'>
<link href='https://fonts.googleapis.com/css?family=Average+Sans' rel='stylesheet' type='text/css'>
<link href='https://fonts.googleapis.com/css?family=Hind' rel='stylesheet' type='text/css'>
-->


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
    <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Emute Lab" />
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-70449773-7', 'auto');
  ga('send', 'pageview');

</script>

</head>


<body>

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->

        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Emute Lab</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">

            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="/">Blog</a>
                </li>
                
                
                <li>

                    <a href="/about">About</a>
                </li>
                
                
                
                
                
                
                
                
                
                <li>

                    <a href="/label">Label</a>
                </li>
                
                
                
                <li>

                    <a href="/news">Events</a>
                </li>
                
                
                
                <li>

                    <a href="/people">People</a>
                </li>
                
                
                
                <li>

                    <a href="/z_contact">Contact</a>
                </li>
                
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>


    <!-- Post Header -->
<header class="intro-header" style="background-image: url('/img/aimclogoSMALL.png')">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <h1>Post-AIMC 2023 Reflection</h1>
                    
                    <span class="meta">Posted by Thor Magnusson and Chris Kiefer on September 5, 2023</span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">

				<p><a href="http://aimc2023.pubpub.org"><img src="/img/aimclogo.png" width="100%" /></a></p>

<h3 id="reflecting-on-aimc-2023">Reflecting on AIMC 2023</h3>

<p>In September 2023 two research labs focussing on musical instruments and live performance came together to run the <strong>International Conference on Artificial Intelligence and Music Creativity</strong>, or <a href="https://aimc2023.pubpub.org">AIMC 2023</a>. After our application to the <a href="https://aimusiccreativity.org">AI and Music Creativity</a> board, it was decided that we would run the 2023 conference at the University of Sussex with the theme of “Intelligent Performance Systems”.</p>

<p>The two labs organising the conference were:</p>

<p><a href="http://www.emutelab.org">Experimental Music Technologies Lab</a></p>

<p><a href="http://www.iil.is">Intelligent Instruments Lab</a></p>

<p>The conference had 75 submissions from all over the world across diverse tracks (papers, demos, doctoral consortium and performances). We also had 14 Alt-AIMC submissions, but the idea with the “Alt” is to allow for late breaking, unfinished or controversial work. Those were judged by the jury and not double blind peer-reviewed like the academic papers. 85 people registered to the conference and in addition to the Sussex and Icelandic teams, we were around 100 people participating.</p>

<hr />

<h3 id="conference-format-and-proceedings">Conference format and Proceedings</h3>

<p>The conference had two keynotes, paper sessions (5 min lightning talks, followed by poster sessions), performances, workshops, demos and an algorave.</p>

<p>Check the website here: <a href="https://aimc2023.pubpub.org">AIMC 2023</a></p>

<p>The AIMC 2023 proceedings can be found <a href="http://www.aimc2023.org/proceedings">here</a></p>

<hr />

<h3 id="streamed-video-recordings-of-all-sessions">Streamed Video Recordings of all sessions</h3>

<p><strong>Keynote 1 - Dadabots</strong></p>

<p>CJ gave a keynote on neural synthesis and the training of audio diffusion models.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/hsVMs2k0vck?si=-GNOxVGSZLhjmJh_" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<hr />

<p><strong>Keynote 2 - Elaine Chew</strong></p>

<p>Elaine Chew, who runs the <a href="https://cosmos.isd.kcl.ac.uk">COSMOS project</a> presented her past work in the field of computational analysis of musical creativity.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/Jtb6tYH4XaE?si=jLFrDTecpTi6Scjq" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
<p><br /></p>

<p>Elaine wrote a <a href="https://cosmos.isd.kcl.ac.uk/?p=4286">blog post</a> about her participation at AIMC.</p>

<p>Information on both keynote speakers can be found <a href="https://aimc2023.pubpub.org/keynotes">here</a></p>

<hr />

<p><strong>Industry Panel</strong></p>

<p><a href="http://www.olliebown.com">Ollie Bown</a> organised an industry panel with <a href="https://dadabots.com">CJ of Dadabots</a>, <a href="https://samim.io">Samim Winiger</a>, <a href="https://www.kcl.ac.uk/people/elaine-chew">Elaine Chew</a>, and <a href="https://www.ryangroves.com">Ryan Groves</a>.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/Dat1P9oa5QE?si=edP3KjZbLyrrwcKM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<hr />

<p><strong>Paper session 1 (incl. Alt-AIMC and Demos)</strong></p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/xmRRu5yfCF8?si=re1Pf-iRelwZMtJt" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p><br />
<strong>Main Papers/Posters</strong></p>

<p>“Bela-IREE: An Approach to Embedded Machine Learning for Real-Time Music Interaction” Ezra Pierce, Victor Shepardson, Jack Armitage, Thor Magnusson</p>

<p>“[neuralnet]: A Pure Data External for the Creation of Neural Networks Written in Pure C” Alexandros Drymonitis</p>

<p>“NeuralMidiFx: A Wrapper Template for Deploying Neural Networks as VST3 Plugins” Behzad Haki, Julian Lenz, Sergi Jorda</p>

<p>“Exploring Latent Spaces of Tonal Music using Variational Autoencoders” Nádia Carvalho, Gilberto Bernardes de Almeida</p>

<p>“Emotional Machines” Jorge Forero, Mónica Mendes, Gilberto Bernardes</p>

<p>“Finetuning Rolypoly~ 2.0: an expressive drum machine that adapts with every performance” Grigore Burloiu</p>

<p><strong>Alt-AIMC Papers/Posters</strong></p>

<p>“AI in live coding environments: Pandora’s Dream” Celeste Betancur Gutierrez</p>

<p>“Latent Space Explorer” Alexander Lunt, Sebastian Trump</p>

<p>“Investigation of Live Coding Using a Combination of ChatGPT and Fine-Tuned GPT-3” Tomoki Okuda and  Kazuhiro Jo</p>

<hr />

<p><strong>Paper session 2 (incl. Alt-AIMC and Demos)</strong></p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/zFYlFZh1sw0?si=qTSbjzw4NqT-8-yz" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p><br /></p>

<p><strong>Main Papers/Posters</strong></p>

<p>“The Phenomenology of Deconstructivist Aesthetics in Music: An Autoethnography of Errors, Erasures, Permutations, Discontinuities, Paradoxes and Artificial Intelligences” Philon Nguyen, Eldad Tsabary</p>

<p>“Music AI’s Potential Impact: Scoping the terms of the debate about value” Oliver Bown</p>

<p>“Caring Trouble and Musical AI: Considerations towards a Feminist Musical AI” Kelsey Cotton, Kıvanç Tatar</p>

<p>“YouTube Mirror: An Interactive Audiovisual Installation based on Cross-Modal Generative Modeling” Sihwa Park</p>

<p>“Risks and Opportunities from Artificial Creativity” Roisin Loughran</p>

<p>“Extensible Embodied Knowledge: Bridging Performance Practice and Intelligent Performance System Design” Lucy Strauss, Matthew Yee-King</p>

<p>“The A in AIMC” Thor Magnusson</p>

<p><strong>Alt-AIMC Papers/Posters</strong></p>

<p>“Are we solving the wrong problems - and doing harm in the process?” Anna-Kaisa Kaila, Andre Holzapfel, Bob L. T. Sturm</p>

<p>“Beyond mutation: how can we acknowledge symbiogenesis in evolutionary music coding?” Matthias Jung</p>

<hr />

<p><strong>Paper session 3 (incl. Alt-AIMC and Demos)</strong></p>

<p><br /></p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/eTHkk1eT7I4?si=bf8pul0sUzFE9iI8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p><br /></p>

<p><strong>Main Papers/Posters</strong></p>

<p>“Musical and Meta-Musical Conversations” Oded Ben-Tal, David Dolan</p>

<p>“Silicon for Orchestra and Artificial Intelligence: Three Strategies for Incorporating Artificial Intelligence into the Compositional Process of Orchestral Music” Robert Laidlow</p>

<p>“Human-AI Musicking: A Framework for Designing AI for Music Co-creativity” Craig Vear, Steve Benford, Juan Martinez Avila, Solomiya Moroz</p>

<p>“Revisiting Reynolds - Autonomous Agents for Spatial Audiovisual Composition and Performances” Damian Dziwis</p>

<p>“Liveness and machine listening in musical live coding: A conceptual framework for designing agent-based systems” Georgios Diapoulis</p>

<p>“Virtual AI Jam: AI-Driven Virtual Musicians for Human-in-the-Loop Musical Improvisation” Torin Hopkins, Alvin Jude, Greg Phillips, Ellen Do</p>

<p><strong>Alt-AIMC Papers/Posters</strong></p>

<p>“Introducing the Caulsio: using causal inference to influence collaboration in a shared music making environment” Steve Symons</p>

<p>“Accessible Co-Creativity through Language and Voice Input” Prateek Verma, Constantin Basica, Patricia Alessandrini, Alexandru Berceanu</p>

<p>“Intimate Musical Collaboration with a Probabilistic Model” Karl Johannsson</p>

<hr />

<p><strong>Paper session 4 (incl. Alt-AIMC and Demos)</strong></p>

<p><br /></p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/1oOr3EnMn_o?si=jOC-hTef1zqAzg5x" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p><br /></p>

<p><strong>Main Papers/Posters</strong></p>

<p>“Sequential Pitch Distributions for Raga Detection” VISHWAAS NARASINH, SENTHIL RAJA G</p>

<p>“The Ai Music Generation Challenge 2022: Summary and Results” Bob L. Sturm</p>

<p>“Statistical evaluation of abc-formatted music at the levels of items and corpora” Laura Cros Vila, Bob L. T. Sturm</p>

<p>“Parsing musical structure to enable meaningful variations” Maziar Kanani, Seán O’Leary, James McDermott</p>

<p>“Deep Learning with Audio: An Explorative Syllabus for Music Composition and Production” Koray Tahiroglu, Shenran Wang, Eduard Mihai Tampu, Jackie Lin</p>

<p>“Are words enough? On the semantic conditioning of affective music generation.” Jorge Forero, Gilberto Bernardes, Mónica Mendes</p>

<p><strong>Alt-AIMC Papers/Posters</strong></p>

<p>“Closing the Loop: Enabling User Feedback and Testing in Symbolic Music Generation through a Python Framework and Ableton Live Integration” Rui Guo</p>

<p>“Introductory Studies on Raga Multi-track Music Generation of Indian classical music using AI” Sreekanth Gopi, Femi William</p>

<p>“Building a Nature Soundscape Generator for the Post-Biodiversity Future” Avery Bick</p>

<hr />

<p><strong>Closing Session</strong></p>

<p><br /></p>

<p>Thor Magnusson and Chris Kiefer reflecting upon the conference and Oded Ben-Tal introduces AIMC 2024 in Oxford.</p>

<p><br /></p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/yC1PvuW2EWQ?si=hYqFBFNyP-qKpCEg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<hr />

<p><strong>Concert 1 in ACCA</strong></p>

<p><br /></p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/EZEnqwB1b2w?si=_vZFH1DRMLKCiffi" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p><br /></p>

<p><em>Odd Couple</em>, Oded Ben-Tal and David Dolan, piano and computer.</p>

<p><em>Organic Algorithmic Composition</em>, Gyuchul Moon.</p>

<p><em>Quantum Fantasy</em>, Jeff Morris. For Conductor and Computer.</p>

<p><em>AI</em>, Franziska Schroeder and Federico Rueben. Saxophone and live coding.</p>

<hr />

<p><strong>Concert 2 in ACCA</strong></p>

<p><br /></p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/xpN5Bxvkq08?si=WMbaQJczMJ_u1tez" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p><br /></p>

<p><em>One, Two, Many</em>, Oded Ben-Tal. For two flutes and computer. Rowland Sutherland on flute 1.</p>

<p><em>iː ɡoʊ weɪ</em>, by Jonathan Reus. For Computer and Voice.</p>

<p><em>Notochord Arcs and scrambled Signals</em>, Victor Shepardson and Nicola Privato. For two computers and human operators.</p>

<p><em>SCAMP Singularity</em>, Henrique Portovedo. Augmented Saxophone and Computer.</p>

<p><em>The historically Informed AI: Johann Sperger through Time and Bass, for Contrabass, Viola, Magnetic Discs and Computer. Based on Sonata for Contrabass and Viola by Johann Matthias Sperger (1777)</em>. Darija Andzakovic , Natalia Duarte, and Nicola Privato.</p>

<hr />

<p><strong>Algorave in Brighton</strong></p>

<p><br /></p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/d0RMUqcbhmQ?si=mwIWSFH21HQFXtjQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p><br /></p>

<p><em>Uncanny</em>, Begüm Çelik and Tuğrul Veli Şalcı</p>

<p><em>Cartographic</em>, Tasos Asonitis</p>

<p><em>James GM (Live) - Machine Learning And Audio-Visual Performance In Unreal Engine 5</em>, James Gibbons-MacGregor</p>

<p><em>drum.code</em>, Timo Hoogland</p>

<p><em>Pandora’s Dream</em>, Celeste Betancur Gutierrez</p>

<p><em>Live Coding with an Affective Autonomous Agent in TidalCycles- Performance</em>, Liz Wilson</p>

<p><em>Gagnavera</em>, Jack Armitage</p>



                <hr>

                <!-- Thor adding twitter -->

                

                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/blog/FMN_Meeting-House" data-toggle="tooltip" data-placement="top" title="New Release on Emute: Live at the Meeting House">&larr; Previous Post</a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/blog/Bristronica" data-toggle="tooltip" data-placement="top" title="Emute Lab @ Machina Bristronica">Next Post &rarr;</a>
                    </li>
                    
                </ul>

            </div>
        </div>
    </div>
</article>
<hr>

	




    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    <li>
                        <a href="/feed.xml">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    <li>
                        <a href="https://twitter.com/emutelab">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li>
                        <a href="https://www.facebook.com/emutelab">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li>
                        <a href="https://github.com/emutelab">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                </ul>
                <p class="copyright text-muted">Copyright &copy; Emute Lab 2024</p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/clean-blog.min.js "></script>


</body>

</html>
