<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Emute Lab</title>
    <description>A Music Informatics and Performance Technologies Lab based in the School of Media, Film and Music at the University of Sussex</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Tue, 10 Oct 2017 14:31:03 +0100</pubDate>
    <lastBuildDate>Tue, 10 Oct 2017 14:31:03 +0100</lastBuildDate>
    <generator>Jekyll v3.6.0</generator>
    
      <item>
        <title>Visiting Researcher: Alberto Novello</title>
        <description>&lt;p&gt;&lt;b&gt;:::: Thursday, October 26th, 1.00pm @ SHL ::::&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;In October, the Emute Lab visiting researcher, Alberto Novello, will give a talk about his research and musical practice. Alberto is a specialist in analogue synthesis, the use of lasers and brain interfaces. In his talk he will present resent work in this area, show videos and play examples.&lt;/p&gt;

&lt;p&gt;All welcome @ the Sussex Humanities Lab, Silverstone Building, 2nd floor.&lt;/p&gt;

&lt;p&gt;Talk Title: &lt;br /&gt;
&lt;b&gt;Invisible to visible: bio signals and possible applications in the arts.&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;In the lecture I will present my body of work, with a particular emphasis on the bio data installations and performances. I will talk about aesthetics of bio signal performances and the correlated dramaturgical limitations. I will explain the approach I followed when creating Fragmentation, UN (focussed) and Brain Pong: my three works using EEG signals. I will explain the techniques and mathematical tools I used and discuss/criticize the final results.&lt;/p&gt;

&lt;p&gt;After the lecture there will be a workshop on the same topic, open to all:&lt;/p&gt;

&lt;p&gt;The focus of the workshop is to get first acquainted with the hardware: two EEG headsets will be compared in their level of complexity to setup vs quality of their data. The workshop will also talk about the possible alternatives on the market the pros and cons of the most common headsets around. The second part of the workshop will focus on software and data analysis: what kind of high-level features can we extract from the raw EEG data? How should we treat that data to extract for example energy bands? What do those band mean and how do they correlate with our everyday brain activity? In the third part, the participants will be encouraged to imagine a possible short performance/installation and, in groups, try and sketch a possible code for it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/novello.jpg&quot; alt=&quot;Novello&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Alberto Novello is a scientist, composer, sound and video artist. His main artistic focus is directed towards the creation of probabilistic multi-media architectures, on the technological limit between instability and error, failure and expression. Lately he moved from digital systems to analog found or decontextualized electronic ensembles.&lt;/p&gt;

&lt;p&gt;He graduated in Nuclear Physics at the University of Trieste, completed the master “Art, Science and Technologies” with Jean Claude Risset and Claude Cadoz, he obtained a PhD degree at the Technische Universiteit Eindhoven with Armin Kohlrausch and graduated in electroacoustic music composition at the Institute of Sonology, Royal Conservatory of Den Haag with Paul Berg, Joel Ryan, and Richard Barret. In his works, he has assisted Alvin Lucier, Nicholas Collins and Trevor Wishart. In the years he also worked Philips Research, Eindhoven, and Auro Technologies Belgium creating software for their audio application.&lt;/p&gt;

&lt;p&gt;His artistic works have been presented in international festivals such as Amsterdam Dance Event, Venice Biennale, Impuls Tanz Vienna, Seoul International Music Festival, Emu Fest Roma, Monaco Electroacoustique, New York Computer Music Festival, Rewire Festival and conferences such as NIME, ICMC, ISMIR, ICMPC, ICA, ICCE and ESSEM and institutes for contemporary music research such as CCMAS in Mexico, GRM in France, Logos Foundation in Belgium, STEIM Amsterdam, IEM Graz, OMI New York, the Royal Conservatory of Den Haag, Conservatory of Padua.&lt;/p&gt;

&lt;p&gt;He was part of the Sonology Electroacoustic Ensemble. He has released his works on CD/DVD as “JesterN’ for Dobialabel, Modisti, Bowindo, SONMA Archive and Hybrida records.&lt;/p&gt;

&lt;p&gt;Novello has improvised with Evan Parker and Butch Morris, Karl Berger and composed for the choreographies of Ola Maciejewska and Liat Waysbort.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;www.jestern.com&quot;&gt;www.jestern.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ALBERTO NOVELLO / JesterN&lt;br /&gt;
site: &lt;a href=&quot;www.jestern.com&quot;&gt;jestern.com&lt;/a&gt;&lt;br /&gt;
shop: &lt;a href=&quot;www.jestern.bandcamp.com&quot;&gt;jestern.bandcamp.com&lt;/a&gt;&lt;br /&gt;
audio: &lt;a href=&quot;www.soundcloud.com/jestern&quot;&gt;soundcloud.com/jestern&lt;/a&gt;&lt;br /&gt;
video: &lt;a href=&quot;www.vimeo.com/jestern&quot;&gt;vimeo.com/jestern&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 05 Oct 2017 00:00:00 +0100</pubDate>
        <link>http://localhost:4000/blog/novello</link>
        <guid isPermaLink="true">http://localhost:4000/blog/novello</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>machine learning</category>
        
        <category>analog synthesis</category>
        
        <category>brain interfaces</category>
        
        <category>laser</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Residency Report: Marije Baalman and Chrysalis</title>
        <description>&lt;p&gt;For the past six days, &lt;a href=&quot;https://www.marijebaalman.eu&quot;&gt;Marije Baalman&lt;/a&gt; has been visiting Sussex for part one of a residency with by EMuteLab and Sussex Humanities Lab.   We’ve been exploring serendipity in mappings for interactive instruments, and focusing on her recent piece &lt;a href=&quot;https://www.marijebaalman.eu/projects/chrysalis.html&quot;&gt;Chrysalis&lt;a&gt;.&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Chrysalis is a cocoon like instrument made from stretch fabric and poles. You crawl into the structure, and when you move around, the wireless accelerometers and stretch sensors (using Marije’s SenseStage system) are mapped to sound and to RGB lights which light up the chrysalis.  Marije wanted to explore new mappings which were less predictable and more engaging to interact with, while at the same time, did not risk moving into modes that were too random or out of keeping with the broad aesthetics of the piece.  Following from some of my &lt;a href=&quot;https://sro.sussex.ac.uk/51860/1/NIME2014-ESN.pdf&quot;&gt;previous work using Echo State Networks&lt;/a&gt; to create complex mappings, we explored Jaeger’s more recent innovations in this area, using a new technique: &lt;a href=&quot;http://minds.jacobs-university.de/conceptors&quot;&gt;Conceptors&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Conceptors essentially capture modes of behaviour of a reccurrent neural network, after which they can be used for pattern generation and for sequence recognition.  When used for pattern generation, they have some very interesting properties: you can mix and morph between patterns and also extrapolate new pattern variations.  This fitted in really well with our aim of encouraging interesting variation in mappings, while staying within a broader aesthetic.  Conceptors allow the creation of new and interesting pattern variations, but without moving too far from the original pattern. In other words, we can create surprises without the risk of them being too surprising.  The addition bonus is that these patterns are generated in real time, and can interact intuitively with sensors. We mapped them to control lighting patterns, and also used the network activations as wavetables to synthesise sound.&lt;/p&gt;

&lt;p&gt;Another innovation was to adapt conceptors for realtime sequence recognition.  This worked successfully with accelerometer data. The way in which conceptors can be used with boolean logic make them a very powerful tool for pattern classification which we will be exploring more before Marije returns for part 2 of her residency in January.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/chrysalis2.jpg&quot; alt=&quot;Chrsalis&quot; /&gt;
&lt;img src=&quot;/img/chrysalis3.jpg&quot; alt=&quot;Chrsalis&quot; /&gt;
&lt;img src=&quot;/img/chrysalis_shl_lightson.jpg&quot; alt=&quot;Chrsalis&quot; /&gt;
&lt;img src=&quot;/img/chrysalis-diag.jpg&quot; alt=&quot;Chrsalis&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 14 Sep 2017 00:00:00 +0100</pubDate>
        <link>http://localhost:4000/blog/chrysalis-report</link>
        <guid isPermaLink="true">http://localhost:4000/blog/chrysalis-report</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>machine learning</category>
        
        <category>live coding</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Chrysalis in the SHL</title>
        <description>&lt;p&gt;&lt;b&gt;
Chrysalis&lt;br /&gt;
When: 13 Sept 2017 - 16:00&lt;br /&gt;
Location: &lt;a href=&quot;http://www.sussex.ac.uk/shl/&quot;&gt;Sussex Humanities Lab&lt;/a&gt;&lt;br /&gt;
&lt;br /&gt;
&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.marijebaalman.eu&quot;&gt;Marije Baalman&lt;/a&gt; is an artist and researcher/developer working in the field of interactive sound art. She is currently visiting Sussex, working with Chris Kiefer on serendipity in interactive machine learning algorithms. They will show the results of their work in a performance with Marije’s latest piece Chrysalis, and discuss the work afterwards in a Q&amp;amp;A session.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/chrysalis.jpg&quot; alt=&quot;Algorave&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 13 Sep 2017 00:00:00 +0100</pubDate>
        <link>http://localhost:4000/blog/chrysalis</link>
        <guid isPermaLink="true">http://localhost:4000/blog/chrysalis</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>machine learning</category>
        
        <category>live coding</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Algorave Brighton 2017</title>
        <description>&lt;p&gt;&lt;b&gt;
Algorave Brighton&lt;br /&gt;
When: 7 Sept 2017 - 19:00–22:30&lt;br /&gt;
Location: &lt;a href=&quot;http://patternsbrighton.com&quot;&gt;Patterns&lt;/a&gt;&lt;br /&gt;
Door tax: FREE&lt;br /&gt;
Facebook event: &lt;a href=&quot;https://www.facebook.com/events/1887328384865474/&quot;&gt;https://www.facebook.com/events/1887328384865474/&lt;/a&gt;&lt;br /&gt;
&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;We are organising an Algorave in Brighton as part of the &lt;a href=&quot;https://www.britishsciencefestival.org&quot;&gt;British Science Festival&lt;/a&gt; programme.&lt;/p&gt;

&lt;p&gt;Algorave is a combination of “algorithms” and “rave”, the opportunity to dance to alien rhythms and freaky visuals, all created from code before your eyes. The Algorave scene is fast-growing around the world, reaching over 50 cities.&lt;/p&gt;

&lt;p&gt;“The scene at an algorave is often what you’d expect from any good techno night - a dark room, engaging visuals. a decent, bass-heavy speaker set-up, and lots of people ready to dance. .. performers at algoraves respond to each other and the audience in real time, often projecting the lines of code onto the walls as they type. lt’s coding as improvisation and experiment..” - The Wire magazine&lt;/p&gt;

&lt;p&gt;“Live coders write computer programs live, while the programs generate their music, but the focus is on people dancing and seriously enjoying themselves” - Dazed and Confused&lt;/p&gt;

&lt;p&gt;”.. not so much a revolution as a de-volution, a rolling back to the backend of music production, where the possibilities of the encoded information inside computer software is open and endless” - Mixmag&lt;/p&gt;

&lt;p&gt;Read a mixmag feature here: &lt;a href=&quot;http://mixmag.net/feature/algorave&quot;&gt;http://mixmag.net/feature/algorave&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Featuring an international lineup of top live coders:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Renick Bell (Tokyo/UIQ+Halcyon Veil)&lt;/li&gt;
  &lt;li&gt;ALGOBABEZ (Leeds+Melbourne/Fractal Meat)&lt;/li&gt;
  &lt;li&gt;Alexandra Cärdenas (Berlin) x Slub (Penryn+Sheffield/Chordpunch)&lt;/li&gt;
  &lt;li&gt;Brighton residents Luuma + Thor Magnusson&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/algorave.jpg&quot; alt=&quot;Algorave&quot; /&gt;
&lt;img src=&quot;/img/bluedot.jpg&quot; alt=&quot;Algorave&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 01 Sep 2017 00:00:00 +0100</pubDate>
        <link>http://localhost:4000/blog/algorave</link>
        <guid isPermaLink="true">http://localhost:4000/blog/algorave</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>algorave</category>
        
        <category>live coding</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Organology Conference Porto</title>
        <description>&lt;p&gt;Emute Lab members Thanos Polymeneas-Liontiris and Thor Magnusson presented work at the &lt;a href=&quot;https://congressorganimusic.wixsite.com/porto2017&quot;&gt;Organology Conference&lt;/a&gt; in Porto, Portugal. The conference consisted of a wide range of instrumental studies, from African and South-American instruments, Baroque flutes and organs, to the volume button in Onde Martenot or Spatial Immersive Instruments.&lt;/p&gt;

&lt;p&gt;We took the opportunity to explore the city, as the biennial &lt;a href=&quot;http://www.liveinterfaces.org&quot;&gt;Live Interfaces Conference&lt;/a&gt; we ran at Sussex last summer will take place in Porto next summer. It promises to be an amazing event, involving &lt;a href=&quot;http://www.casadamusica.com/en/&quot;&gt;Casa De Musica&lt;/a&gt; and many other interesting places in this beautiful city.&lt;/p&gt;

&lt;p&gt;The abstracts from Thanos and Thor follw below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/porto.jpg&quot; alt=&quot;Porto&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Musical Organics: A Heterarchical Approach to Digital Organology&lt;br /&gt;&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;by: Thor Magnusson &lt;b&gt;&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;An important pursuit of organology is the classification of musical instruments. The tree-metaphor has traditionally been the key organisational principle, most prominently applied by Hornbostel and Sachs in their classification from 1914. As Nietzsche, Foucault, and Eco demonstrated, the classification of a domain is an epistemic act; indeed, we find epistemic time periods, where cultures throw different “conceptual nets” over the “rabble of reality” (as Nietzsche put it).
Hornbostel and Sachs acknowledged the problems of division in their classification, stating that instruments are alive and dynamic, whereas systems are static and delineating. This is even more true with new digital instruments, as their complex nature renders them hard to place into classificatory categories. A new analytical approach is required that engages with the repository of digital instruments from a multiplicity of perspectives: materials (e.g., plastic, metal, glass, fibre, cloth); sensors (e.g., ultrasound, bend, potentiometers); sound (e.g., physical models, subtractive, granular, sampling); mapping (e.g., one-to-one, one- to-many, many-to-one, convergent, learned, evolutionary); gestures (e.g., hit, stroke, pluck, shake, bow, blow); reuse of proprioceptive skills (such as the trained playing of keyboard, strings, wind, and percussion); manufacturer (e.g., of sensors, chips, motors), and many more, including cultural context, musical style, and other areas that have been, or indeed will be, called for as extensions to existing organological classifications.&lt;/p&gt;

&lt;p&gt;This presentation will discuss the necessity of shifting our classificatory metaphors from the tree to the rhizome, from hierarchy to heterarchy, pointing to the digital as something that is essentially hard to define due to the lack of tradition, legacy, and institutional framework. The paper discusses the problems of classification of digital instruments and introduce some of the organological work done in the field, leading up to the author’s proposal of Musical Organics. As a theoretical method that applies modern search, machine information retrieval, and representation technologies, musical organics enable researchers to create ad-hoc classifications of instrumental spaces as a collaborative organological research.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;b&gt;Instrumented spaces: two immersive music theatre performances&lt;br /&gt;&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;by: Thanos Polymeneas-Liontiris&lt;b&gt;&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;This presentation revolves around two performances / experiments presented as part of  my research on instrumented/audience reactive sound spaces: Im•medea and the landscape may be a dead star. The works drew inspiration from processes and techniques used in interactive art installations, with the aim of designing and delivering generative Music Theatre.&lt;/p&gt;

&lt;p&gt;Both performances were using the space as an instrument: a series of Infrared (IR) sensors (placed on the walls and ceilings of the spaces) were tracking the movement, position and density of the audience in the rooms. The digital information of these sensors was then analysed and processed by a custom- made algorithm, contributing to the performance in different ways. While in Im•medea it generated the electronic soundscape for the performance, in the landscape may be a dead star it produced the musical score that the performers had to interpret. The result in both cases was an ever-changing music theatre performance, which was evolving by handling the space as an invisible instrument that was played by the movement, position and amount of audience/bodies in space.&lt;/p&gt;

&lt;p&gt;The processes in both performances can be observed as methods for scoring, composing, as well as instruments or performance ecosystems, cybernetic, trans-individual network systems linking audience, performers and technology with a transparent web. These two experiments were the first of a series of experiments of an on-going research on post-digital processes and notions of Posthumanism in Music Theatre.&lt;/p&gt;

</description>
        <pubDate>Wed, 30 Aug 2017 00:00:00 +0100</pubDate>
        <link>http://localhost:4000/blog/organology</link>
        <guid isPermaLink="true">http://localhost:4000/blog/organology</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>organology</category>
        
        <category>NIME</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Event Report: The Forum for Immersive Augmented Reality Instruments</title>
        <description>&lt;p&gt;The &lt;a href=&quot;https://forumarimi.wixsite.com/arimi&quot;&gt;Forum for Immersive Augmented Reality Instruments&lt;/a&gt;, a two-day networking event, took place on June 19-20th. It brought together diverse participants across University of Sussex schools, research centres and labs, together with representatives from local art organisations and creative industries, with a view to understanding cultural transformations from Augmented Reality (AR), and to build new interdisciplinary research partnerships.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/arimiheader.png&quot; alt=&quot;ARImI Header&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The network event was designed to explore new forms of creation, experience and digital culture through tool and instrument-making, whilst achieving independence from existing distribution structures, and bringing together transdisciplinary discussions on condition of ‘seeing’ (Paul &amp;amp; Toolin 2014, p53) as sensing.&lt;/p&gt;

&lt;p&gt;Day one saw presentations from participants under the themes of culture, sensing, instruments and arts.  On day two, participants explored AR practically through two workshops; an ‘unplugged’ workshop where groups built and discussed hypothetical AR technologies, and a ‘plugged’ workshop where groups experimented with off-the-shelf AR technologies, using visual, audio and haptics materials.&lt;/p&gt;

&lt;p&gt;The Forum for ARImI was led by Cécile Chevalier &amp;amp; Chris Kiefer in partnership with Kirk Woolford, University of Surrey. It was supported by the Doctoral School’s Researcher-Led Initiative (RLI) Fund,  the School of Media, Film, and Music, Sussex Humanities Lab &amp;amp; EMuTe Lab.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/arimi1.JPG&quot; alt=&quot;ARImI Unplugged&quot; /&gt;
&lt;img src=&quot;/img/arimi2.JPG&quot; alt=&quot;ARImI Plugged&quot; /&gt;
&lt;img src=&quot;/img/arimi3.JPG&quot; alt=&quot;ARImI Plugged&quot; /&gt;
&lt;img src=&quot;/img/arimi4.JPG&quot; alt=&quot;ARImI Unplugged&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 28 Jun 2017 00:00:00 +0100</pubDate>
        <link>http://localhost:4000/blog/arimi</link>
        <guid isPermaLink="true">http://localhost:4000/blog/arimi</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>augmented reality</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Emute Lab @ NIME</title>
        <description>&lt;p&gt;The Experimental Music Technologies Lab at Sussex will have a strong presence at this year’s &lt;a href=&quot;http://www.nime2017.org&quot;&gt;NIME&lt;/a&gt; (New Interfaces for Musical Expression Conference) which is held by Aalborg University in Copenhagen, Denmark. Cecile Chevalier and Andrew Duff present a sound installation, Alice Eldridge and Chris Kiefer will present a paper on their Feedback Cello project, Thor Magnusson will present his paper on Musical Organics, and Alice, Chris and Thor will perform using the Threnoscope and feedback cellos.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;See project descriptions below:&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Alice Eldridge&lt;/b&gt; and &lt;b&gt;Chris Kiefer&lt;/b&gt; present a paper introducing their &lt;b&gt; feedback cello&lt;/b&gt; project, which is a new electroacoustic actuated instrument in which feedback can be induced independently on each string. Built from retro-fitted acoustic cellos, the signals from electromagnetic pickups sitting under each string are passed to a speaker built into the back of the instrument and a transducer on the front of the instrument. Placement of acoustic and mechanical actuators on the resonant body of the cello, mean that this simple analogue feedback system is capable of a wide range of complex self-resonating behaviours. Their paper describes the motivations for building these instruments as both a physical extension to live computer music practice and an electroacoustic augmentation of cello. The design and physical construction is outlined, and modes of performance described with reference to the first six months of performances and installations. Future developments and planned investigations are described.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/img/feedback_cellos.jpg&quot; alt=&quot;Feedback cellos&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Cecile Chevalier&lt;/b&gt; and &lt;b&gt;Andrew Duff’s&lt;/b&gt; &lt;b&gt;200.104.200.2*&lt;/b&gt; is a sound installation, created as a displaced reenactment of both contemporary digital social practice and the Internet as a memory palace, in which sonifications of memory traces can be performed, stored and replayed as digital data. The work is situated in relation to the art of memory as a form of memory spatialisation, and in relation to post-digital aesthetics, ultimately forming a potential immersive instrument for collective performances. In its conceptual design and instrument-making, 200.104.200.2 is a stainless steel structure 2.5 meters high, 2 meters long and 2 meters wide, from which over 3000 copper wires hang. The structure itself can be entered by participants or performers, as it tracks, connects and extends each of their movements through fine colliding wires that occur within the piece.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/img/cecileinst.jpg&quot; alt=&quot;Feedback cellos&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Thor Magnusson’s&lt;/b&gt; Threnoscope and the Feedback Cello project of &lt;b&gt;Chris Kiefer&lt;/b&gt; and &lt;b&gt;Alice Eldridge&lt;/b&gt; meet for the first time in a performance at NIME. The feedback cellos are built from acoustic instruments that are modified with electromagnetic pick ups, speakers and transducers, to create a self-resonating drone instrument which can be played either within the extended string tradition or live coded. The threnoscope is a software instrument designed for spatialised, microtonal drone music. In this performance, six channel outputs of the Threnoscope are diffused through a quadrophonic system and also sent to the speakers in the two cellos, affecting the resonant landscapes of the instruments which are simultaneously played by Alice and Chris. Acoustic signals from the cellos are also channeled back to the Threnoscope, creating a multi-instrument, multichannel feedback system. Sonic processes which are physically or digitally initiated by the players on discrete instruments influence each other to form a single dynamical drone system; the liveliness of the ensemble-system as a whole outperforms any one of the players.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/img/osc.jpg&quot; alt=&quot;Feedback cellos&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Thor Magnusson&lt;/b&gt; presents a paper entitled &lt;b&gt;Contextualising Musical Organics: Ad-hoc Organological Classification Approach&lt;/b&gt;. Here is the abstract:&lt;/p&gt;

&lt;p&gt;New digital musical instruments are difficult for organologists to deal with due to their heterogeneous origins, cross-disciplinary science, and fluid, open-ended nature. NIMEs are studied from a range of disciplines, such as musicology, engineering, human-computer interaction, psychology, design, and performance studies. Attempts to continue traditional organology classifications for electronic and digital instruments have been made, but with adverse results. This paper discusses the problem of the tree-like classifications of digital instruments, proposing an alternative approach: musical organics. Musical organics is a philosophical approach to the problems inherent in organological classification of digital instruments. Shifting the emphasis from hand-coded classification to information retrieval supported search and clustering, we propose an open and distributed system that anyone can contribute to. In order to show how such a system could incorporate a third-party addition, the paper also presents an organological ontogenesis of three new musical instruments: the saxophone, the Minimoog, and the Reactable. This micro-analysis of innovation in the field of musical instruments can help forming a framework for the study of how instruments are adopted in musical culture.&lt;/p&gt;

&lt;p&gt;Thanks to the School of Media, Film and Music and the Sussex Humanities Lab for the support.&lt;/p&gt;

</description>
        <pubDate>Wed, 05 Apr 2017 00:00:00 +0100</pubDate>
        <link>http://localhost:4000/blog/NIME2017</link>
        <guid isPermaLink="true">http://localhost:4000/blog/NIME2017</guid>
        
        <category>emutelab</category>
        
        <category>NIME</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Emute Lab Meeting: Feedback Cellos!</title>
        <description>&lt;p&gt;&lt;strong&gt;:::: Thursday, March 23rd, 1pm, @ Recital Room, Falmer House 120 ::::&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We have an Emute Lab research lunch meeting on March 23rd, where Alice Eldridge and Chris Kiefer will present the results of their recent work on the feedback cellos, conducted at the Icelandic Academy of the Arts with Halldór Úlfarsson. That was a collaboration that started at the Live Interfaces conference (www.liveinterfaces.org) where Halldór ran a workshop with composers and performers.&lt;/p&gt;

&lt;p&gt;Chris and Alice write:&lt;/p&gt;

&lt;p&gt;We will report on a recent trip to the Iceland Academy of the Arts to visit instrument designer Halldór Úlfarsson, who we have been collaborating with on the design of two Feedback Cellos. These unique hybrid instruments have been evolving quickly since we first made them last summer. We will present the latest developments, and discuss some issues around design and performance that we have been engaging with in this project.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/img/feedback_cellos.jpg&quot; alt=&quot;Feedback cellos&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 20 Mar 2017 00:00:00 +0000</pubDate>
        <link>http://localhost:4000/blog/emutemeeting</link>
        <guid isPermaLink="true">http://localhost:4000/blog/emutemeeting</guid>
        
        <category>emutelab</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>A Magnificent Crossbreeding of Protein and Tinplate</title>
        <description>&lt;p&gt;&lt;strong&gt;:::: Monday, February 13th, 5-9pm @ Attenborouch Centre for the Creative Arts ::::&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;A Magnificent Crossbreeding of Protein and Tinplate is a generative music theatre performance with audience interactive/participatory aspects. It is inspired and devised based on Heiner Muller’s Despoiled Shore/Medeamaterial/Landscape with Argonauts. The audience is invited to explore this performance ecosystem, a deconstructed landscape, a fragmented environment, where individuals can be found playing music, reading, singing, being.&lt;/p&gt;

&lt;p&gt;A Magnificent Crossbreeding of Protein and Tinplate is a posthuman vivarium. The “I” in this space is collective and visitors are invited to transit, inhabit, indulge and experience this world, to interact with the performers, the objects and the space. The piece is an alive performance organism, controlled through a network of computers. It evolves as time passes, and as the performers and the cybernetic system react to the audience’s presence and movement in the space, generating a succession of unique and unexpected situations.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/img/speakofme.jpg&quot; alt=&quot;Shall I speak of me?&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The performance is designed to run for 4 hours and the audience can enter and leave the space as they please. Due to the nature of the performance and the space limitation, the audience might be asked to explore the space carefully, as well as be open for interaction with other human and non-human beings.&lt;/p&gt;

&lt;p&gt;This piece of generative music theatre is the final of a series of experiments, part of Thanos Polymeneas-Liontiris’ PhD practice-based research on interactive music theatre, taking place at the University of Sussex, supervised by Thos Magnusson and Nicholas Till and funded by AHRC.&lt;/p&gt;

&lt;p&gt;Further location info: &lt;a href=&quot;https://www.attenboroughcentre.com/events/681/a-magnificent-crossbreeding-of-protein-and-tinplate/&quot;&gt;ACCA&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Concept/Direction/Music: &lt;a href=&quot;https://www.facebook.com/thanos.polymeneasliontiris&quot;&gt;Thanos Polymeneas Liontiris&lt;/a&gt;
Production/Assistant Director: &lt;a href=&quot;https://www.facebook.com/megdemeg&quot;&gt;M. Eugenia Demeglio&lt;/a&gt;
Text by: H. Muller, Aeschelus, Heracletus, W. Shakespeare, T.S. Elliot, G. Seferis, F. Hölderlin
Text adaptation: Nikos Ioakeim, Thanos Polymeneas-Liontiris
Devised with and performed by: &lt;a href=&quot;https://www.facebook.com/goncalo.almeida.5686&quot;&gt;Gonçalo Almeida&lt;/a&gt; (PT/NL), M. Eugenia Demeglio (IT/UK), &lt;a href=&quot;https://www.facebook.com/profile.php?id=1367346763&quot;&gt;Theresa Elflein&lt;/a&gt; (DE/UK), Nikos Ioakeim (GR/NL), Katerina Kostantourou (GR/NL), &lt;a href=&quot;https://www.facebook.com/art.the.melt&quot;&gt;Arthur Artorius Leadbetter&lt;/a&gt; (UK), &lt;a href=&quot;https://www.facebook.com/frisprit&quot;&gt;Stephanie Pan&lt;/a&gt; (US/NL), &lt;a href=&quot;https://www.facebook.com/friso.vanwijck&quot;&gt;Friso van Wijck&lt;/a&gt; (NL).&lt;/p&gt;
</description>
        <pubDate>Wed, 08 Feb 2017 00:00:00 +0000</pubDate>
        <link>http://localhost:4000/blog/proteintinplate</link>
        <guid isPermaLink="true">http://localhost:4000/blog/proteintinplate</guid>
        
        <category>emutelab</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Emute Lab in Reykjavik</title>
        <description>&lt;p&gt;The fruitful collaboration with &lt;a href=&quot;http://www.halldorulfarsson.info/&quot;&gt;Halldor Ulfarsson&lt;/a&gt; on the feedback cellos, that started as part of the Arts Council funded workshop programme at the &lt;a href=&quot;http://www.liveinterfaces.org&quot;&gt;Live Interfaces conference&lt;/a&gt;, is continuing with Alice Eldridge and Chris Kiefer going to Reykjavik to work at theIcelandic Academy of the Arts.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/img/feedbackcellos.jpg&quot; alt=&quot;Feedback Cellos&quot; /&gt;&lt;/p&gt;

&lt;p&gt;They will also be performing in &lt;a href=&quot;http://www.mengi.net/2017/01/24/17-02/&quot;&gt;Mengi&lt;/a&gt; on February 12th:&lt;/p&gt;

&lt;p&gt;Feedback Cell is the duo formed by cellist Alice Eldridge (Collectress, En Bas Quartet) and computer-musician Chris Kiefer (Luuma) to explore their ever-evolving feedback cello project. Two butchered cellos, electromagnetic pickups, code, bows and lots of soldering. Emits dulcet drones and brutal yelps.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Alice Eldridge&lt;/b&gt; is a cellist and researcher. Her backgrounds in music, psychology, evolutionary and adaptive systems and computer science inspires and informs systemic sound-based research across ecology, technology and music. Current projects include ecoacoustics for biodiversity assessment, networked notation for ensemble music-making and hybrid instrument building for improvisation. As a cellist she has shared stages, studios and other acoustic spaces with some of the UK’s most inventive musicians at the intersections of contemporary classical, folk, free jazz, minimal pop and algorithmic musics.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Chris Kiefer&lt;/b&gt; is a computer-musician and musical instrument designer, specialising in musician-computer interaction, physical computing, and machine learning. He performs with custom-made instruments including malleable foam interfaces, touch screen software, interactive sculptures and a modified self-resonating cello. Chris’ research often focuses on participatory design and development of interactive music systems in everyday settings, including digital instruments for children with disabilities, and development of the NETEM networked score system for musical ensembles.&lt;/p&gt;

&lt;p&gt;The concert starts at 9pm.&lt;/p&gt;

&lt;p&gt;Tickets: 2000 ISK.&lt;/p&gt;
</description>
        <pubDate>Tue, 07 Feb 2017 00:00:00 +0000</pubDate>
        <link>http://localhost:4000/blog/reykjavik</link>
        <guid isPermaLink="true">http://localhost:4000/blog/reykjavik</guid>
        
        <category>emutelab</category>
        
        
        <category>blog</category>
        
      </item>
    
  </channel>
</rss>
