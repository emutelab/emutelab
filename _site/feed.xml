<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Emute Lab</title>
    <description>A Music Informatics and Performance Technologies Lab based in the School of Media, Film and Music at the University of Sussex</description>
    <link>http://www.emutelab.org/</link>
    <atom:link href="http://www.emutelab.org/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Fri, 26 Jun 2020 10:52:29 +0100</pubDate>
    <lastBuildDate>Fri, 26 Jun 2020 10:52:29 +0100</lastBuildDate>
    <generator>Jekyll v3.1.6</generator>
    
      <item>
        <title>Emute Lab at NIME 2020</title>
        <description>&lt;p&gt;&lt;strong&gt;:::: Emute Lab at NIME 2020 ::::&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Emute Lab member have a number of contributions to New Interfaces for Musical Expression 2020, taking place online in late July.&lt;/p&gt;

&lt;p&gt;We begin with a lab report, on our recent activities, and our wider philosophy and approach.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Instrumental Investigations at the Emute Lab&lt;/em&gt;&lt;/strong&gt;
&lt;em&gt;Thor Magnusson, Alice Eldridge and Chris Kiefer&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;This lab report discusses recent projects and activities of the Experimental Music Technologies Lab at the University of Sussex. The lab was founded in 2014 and has contributed to the development of the field of new musical technologies. The report introduces the lab’s agenda, gives examples of its activities through common themes and gives short description of lab members’ work. The lab environment, funding income and future vision are also presented.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The remaining contributions centre around a big research topic in Emute Lab, feedback instruments and musicianship.  Halldór Úlfarsson collaborates on two submissions, firstly a paper:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Sculpting the behaviour of the Feedback-Actuated
Augmented Bass&lt;/em&gt;&lt;/strong&gt; &lt;em&gt;Halldór Úlfarsson and Adam Pultz Melbye (Sonic Arts Research Centre, Belfast)&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;This paper describes physical and digital design strategies for the Feedback-Actuated Augmented Bass – a self-contained feedback double bass with embedded DSP capabilities. A primary goal of the research project is to create an instrument that responds well to the use of extended playing techniques and can manifest complex harmonic spectra while retaining the feel and sonic fingerprint of an acoustic double bass. While the physical configuration of the instrument builds on similar feedback string instruments being developed in recent years, this project focuses on modifying the feedback behaviour through low-level audio feature extractions coupled to computationally lightweight filtering and amplitude management algorithms. We discuss these adaptive and time-variant processing strategies and how we apply them in sculpting the system’s dynamic and complex behaviour to our liking.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/376697035&quot; width=&quot;640&quot; height=&quot;360&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;a href=&quot;https://vimeo.com/376697035&quot;&gt;The Augmented Double Bass (listen with headphones)&lt;/a&gt; from &lt;a href=&quot;https://vimeo.com/user27144102&quot;&gt;Adam Pultz Melbye&lt;/a&gt; on &lt;a href=&quot;https://vimeo.com&quot;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Halldór also collaborates on a performance.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Dual/Duel/Duet/for/with/halldorophone&lt;/em&gt;&lt;/strong&gt; &lt;em&gt;Nicole Robson (Queen Mary, University of London) and Halldór Úlfarsson&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The halldorophone is a cello-like, feedback instrument, developed over the past decade by Halldór Úlfarsson. The
instrument is well-established in experimental music circles and gaining wider recognition thanks to its use by composer
and cellist Hildur Guðnadóttir in film scores, including her Oscar nominated music for Joker (2019). The halldorophone
utilises a simple system, whereby the vibration of each string is detected by a pickup, amplified and routed to a speaker
embedded in the back of the instrument. By adding gain to individual strings in the feedback loop, the instrument’s
response can become rapidly complex, potentially spinning out of control. While every musical performance of a
piece is unique in some way and contingent on its particular moment and situation in time, the unstable nature of the
halldorophone exacerbates this condition. Players describe the halldorophone as ‘unpredictable’, ‘very much alive’ and
as having ‘its own ideas’, even tiny changes to their body position in performance might produce unexpected effects
. In this NIME premiere for the instrument, cellist Nicole Robson will perform a piece for a new digitally endowed
halldorophone, and the title of the piece – Dual/Duel/Duet – acknowledges the active role of the instrument in shaping
the composition and performance.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://www.halldorophone.info/public/img/2018-Square.jpg&quot; alt=&quot;Sister 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Next up is a paper on complexity and the behaviour of feedback instruments.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Shaping the behaviour of feedback instruments with complexity-controlled gain dynamics&lt;/em&gt;&lt;/strong&gt; &lt;em&gt;Chris Kiefer, Dan Overholt (Aalborg University, Copenhagen), Alice Eldridge&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Feedback instruments offer radical new ways of engaging
with instrument design and musicianship. They are defined
by recurrent circulation of signals through the instrument,
which give the instrument ‘a life of its own’ and a ’stimulating uncontrollability’. Arguably, the most interesting
musical behaviour in these instruments happens when their
dynamic complexity is maximised, without falling into saturating feedback. It is often challenging to keep the instrument in this zone; this research looks at algorithmic ways
to manage the behaviour of feedback loops in order to make
feedback instruments more playable and musical; to expand
and maintain the ‘sweet spot’. We propose a solution that
manages gain dynamics based on measurement of complexity, using a realtime implementation of the Effort to Com-
press algorithm. The system was evaluated with four musicians, each of whom have different variations of string-based
feedback instruments, following an autobiographical design
approach. Qualitative feedback was gathered, showing that
the system was successful in modifying the behaviour of
these instruments to allow easier access to edge transition
zones, sometimes at the expense of losing some of the more
compelling dynamics of the instruments. The basic efficacy
of the system is evidenced by descriptive audio analysis.
This paper is accompanied by a dataset of sounds collected
during the study, and the open source software that was
written to support the research.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Finally, we’ll be running a &lt;strong&gt;&lt;em&gt;workshop on Feedback Musicianship&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Workshop Aim: Exchange and generation of strategies, concepts and practices of feedback musicianship – building community, new musical collaborations
Feedback purposefully utilised in performance has long been an interesting musical endeavour; however, integrating such expertise into the design and development of instruments and interactive systems, which balance autonomy and expressivity, playability and musicality remains a challenge. Examples include extended traditional instruments, modular synthesisers, feedback incorporated into acoustic resonating bodies, new algorithmic techniques for managing feedback loops, etc. The workshop will conclude with an evening concert (online informal jam session) in the form of improvisation with feedback instruments, open to all participants. Identifying the importance of musical feedback in interaction, instruments, and systems, this workshop focuses on the development of instruments for innovative interactions with feedback in music, from designs for feedback instruments themselves, to novel multi-sensory interaction with feedback incorporated into augmented instruments and systems.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;You can see more details and sign up here:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://nime2020.bcu.ac.uk/feedback-musicianship/&quot;&gt;https://nime2020.bcu.ac.uk/feedback-musicianship/&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 26 Jun 2020 00:00:00 +0100</pubDate>
        <link>http://www.emutelab.org/blog/emute-at-nime</link>
        <guid isPermaLink="true">http://www.emutelab.org/blog/emute-at-nime</guid>
        
        <category>emutelab</category>
        
        <category>nime</category>
        
        <category>lab report</category>
        
        <category>feedback</category>
        
        <category>paper</category>
        
        <category>poster</category>
        
        <category>workshop</category>
        
        <category>performance</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Sema: Live Coding With Machine Learning Workshop</title>
        <description>&lt;p&gt;&lt;strong&gt;:::: When: June 29th - July 3rd, 3-5pm UK time. Where: Zoom ::::&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Would you like to use &lt;b&gt;machine learning as part of musical live coding&lt;/b&gt;? Would you like to create your own live coding language? We are inviting you to participate in a free workshop that will take place online in early July. With daily videos, Zoom sessions and follow-up online hangouts, we will get you up and running in using our new technologies for using AI in live coding.&lt;/p&gt;

&lt;p&gt;As part of our work in the &lt;a href=&quot;http://www.mimicproject.com&quot;&gt;MIMIC project&lt;/a&gt;, we have created &lt;b&gt;Sema&lt;/b&gt;: an online system for live coding with AI in the browser. Here you can apply many of the machine learning technologies we have implemented as part of our MIMIC work, but moreover: you can design your own live coding language!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/Semascreenshot.png&quot; alt=&quot;Screenshot of Sema&quot; /&gt;
&lt;em&gt;A screenshot of Sema. Take a look at the three videos of Sema in action below.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We believe every new live coding language results in new musical approaches, which implies that for a diversity of music we need a diversity of languages. Sema enables you to write your own language, whether it is one piece of music, an instrument, a pattern generator, or a full blown live coding language.&lt;/p&gt;

&lt;p&gt;Sema will be officially launched just before the start of the workshop, so you will be one of the first users to test this new technology and design your own live coding languages for machine learning in music.&lt;/p&gt;

&lt;p&gt;There is no previous experience required to participate in this Sema workshop. Although you do not need any machine learning expertise, you will benefit from beginner-level JavaScript programming skills. You don’t even have to be an experienced musician. This workshop will introduce the basic concepts of musical live coding with AI, and get people up to speed in using Sema and creating their own live coding languages. We are hoping that workshop participants will contribute in a user-study that will help us to develop the system further.&lt;/p&gt;

&lt;p&gt;We will run a flipped-learning workshop where we release introductory tutorial videos each day and workshop participants study them in their own time. We then have a synchronous Zoom Q&amp;amp;A workshop session at 3pm every day.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Programme of the Workshop Week:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Monday - June 29th&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;all day - Introduction (YouTube videos): Introduction to Sema and the default Sema language
3pm - Workshop (Zoom): Making music with the Sema default language + QnA
5pm - Slack channel: Discussion
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Tuesday - June 30th&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;all day - Introduction (YouTube Videos): Machine Learning concepts. Using machine learning in Sema
1pm - Slack channel: Discussion and work
3pm - Workshop (Zoom): Making music with machine learning. Training a ML network + QnA
4pm - Slack channel: Discussion
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Wednesday - July 1th&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;all day - Introduction (YouTube Videos): Machine learning libraries. FFT and machine learning
1pm - Slack channel: Discussion and work
3pm - Workshop (Zoom): Machine listening and machine learning
4pm - Slack channel: Discussion
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Thursday - July 2nd&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;all day - Introduction (YouTube Videos): Language design in Sema. How to create your own live coding language
1pm - Slack channel: Discussion and work
3pm - Workshop (Zoom): Making your own piece with unique language syntax
5pm - Slack channel: Discussion
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Friday - July 3rd&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;all day - Introduction (YouTube Videos): Language design for machine learning	
1pm - Slack channel: Discussion and work
3pm - Workshop (Zoom): Finishing your live coding language + QnA
5pm - Showcase of projects in development (or ideas). Drinks and snack.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Additional Support the Following Week:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Monday - July 6th&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;3pm - Project Development (Zoom): A session where we support people completing their projects
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Wednesday - July 8th&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;3pm - Project Development (Zoom): A session where we support people completing their projects
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Friday - July 10th&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;3pm - Project Development (Zoom): A session where we support people completing their projects
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Registration:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;A sign-up and further information about the workshop: &lt;a href=&quot;https://bit.ly/30OomUo&quot;&gt;Sema Workshop Registration&lt;/a&gt;&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;This video demonstrates the &lt;b&gt;default language&lt;/b&gt; of Sema and some of its functionality&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/7Cu2R66OTak&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;In this video we have a new language, called &lt;b&gt;Rubber Duckling&lt;/b&gt;, and we demonstrate some basic rhythm functionality.&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/Qw4sYnTj-Ow&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;This video shows the binary language called &lt;b&gt;Nibble&lt;/b&gt;. It functions by swapping bits around.&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/6wIgZ-Vymas&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;These videos are small examples of what can be done with Sema. It is really up to you to decide what you will do with this system.&lt;/p&gt;

&lt;p&gt;For a more technical information about Sema, please refer to these articles:&lt;/p&gt;

&lt;p&gt;Bernardo, F., Kiefer, C., Magnusson, T. (2019). An AudioWorklet-based Signal Engine for a Live Coding Language Ecosystem. In Proceedings of Web Audio Conference 2019, Norwegian University of Science and Technology (NTNU), Trondheim, Norway (Best Paper Award at Web Audio Conference 2019)
&lt;a href=&quot;https://webaudioconf.com/_data/papers/pdf/2019/2019_40.pdf&quot;&gt;https://webaudioconf.com/_data/papers/pdf/2019/2019_40.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;C. Kiefer and T. Magnusson. Live Coding Machine Learning and Machine Listening: A Survey on the Design of Languages and Environments for Live Coding. In Proc. of the International Conference on Live Coding., Madrid, 2019.
&lt;a href=&quot;https://iclc.toplap.org/2019/papers/paper97.pdf&quot;&gt;https://iclc.toplap.org/2019/papers/paper97.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Bernardo, F., Kiefer, C., Magnusson, T. (2020). Designing for a Pluralist and User-Friendly Live Code Language Ecosystem with Sema. 5th International Conference on Live Coding, University of Limerick, Limerick, Ireland&lt;/p&gt;

&lt;p&gt;Bernardo, F., Kiefer, C., Magnusson, T. (forthcoming). A Signal Engine for a Live Code Language Ecosystem. Journal of Audio Engineering Society, Vol. 68, No. 1, October&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Please register above and we hope to see you on Zoom, from June 29th!&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;(Francisco, Chris and Thor)&lt;/p&gt;

</description>
        <pubDate>Tue, 16 Jun 2020 00:00:00 +0100</pubDate>
        <link>http://www.emutelab.org/blog/Semaworkshop</link>
        <guid isPermaLink="true">http://www.emutelab.org/blog/Semaworkshop</guid>
        
        <category>emutelab</category>
        
        <category>workhop</category>
        
        <category>live coding</category>
        
        <category>machine learning</category>
        
        <category>language design</category>
        
        <category>summer</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Performance Lecture: David Rothenberg</title>
        <description>&lt;p&gt;&lt;b&gt;:::: Thursday, May 7th, 4.00pm ONLINE ::::&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Performance Lecture: &lt;b&gt;The Virtual Nightingale&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;i&gt;Have you found that you have paid more attention to the birds and the bees during lock down?&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;To segue from International Dawn Chorus Day and continue the celebration of our soniferous cousins, we are thrilled to host a special guest from across the pond.&lt;/p&gt;

&lt;p&gt;David Rothenberg, author of &lt;strong&gt;Why Birds Sing&lt;/strong&gt; and &lt;strong&gt;Nightingales in Berlin&lt;/strong&gt;, veteran performer with nature sounds near and far,
will discuss his work with nightingales and underwater pond insects, explaining why human music can be enhanced by taking
the sounds of the natural world seriously.&lt;/p&gt;

&lt;p&gt;This event is free and open to all.  See bottom for registration details.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://scontent-lhr8-1.xx.fbcdn.net/v/t1.0-9/95500812_644695099715434_6391060066870493184_o.jpg?_nc_cat=111&amp;amp;_nc_sid=b386c4&amp;amp;_nc_ohc=qQ8Upx15yEsAX-77h8n&amp;amp;_nc_ht=scontent-lhr8-1.xx&amp;amp;oh=bb4c10ed93adb42a950191cd1d937782&amp;amp;oe=5ED6EC87&quot; alt=&quot;rothenberg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Dr. David Rothenberg is distinguished professor of philosophy and music at the New Jersey Institute of Technology.  He is a noted writer on themes connecting humanity, nature, and technology and music.  He is the author of Why Birds Sing (Basic Books and Penguin UK, 2005), also published in Italy, Spain, Taiwan, China, Korea, and Germany, and turned into a feature-length documentary &lt;em&gt;Why Birds Sing&lt;/em&gt; by Endemol UK for BBC4 in June, 2007.  Rothenberg is also the author of &lt;em&gt;Hand’s End: Technology and the Limits of Nature&lt;/em&gt; (California, 1993), &lt;em&gt;Thousand Mile Song&lt;/em&gt; (Basic Books, 2008),  &lt;em&gt;Survival of the Beautiful&lt;/em&gt; (Bloomsbury, 2011), Bug Music (St Martins, 2013) and &lt;em&gt;Nightingales in Berlin&lt;/em&gt; (Chicago, 2019 and Rowohlt, 2020)&lt;/p&gt;

&lt;p&gt;As a musician Rothenberg records for the prestigious ECM label.  His CD &lt;em&gt;One Dark Night I Left My Silent House&lt;/em&gt;,  a duet album with pianist Marilyn Crispell, was called “une petite miracle” by Le Monde and named by The Village Voice one of the ten best CDs of 2010.  He has performed or recorded with Peter Gabriel, Scanner, Suzanne Vega, Marilyn Crispell, Pete Seeger, and Jaron Lanier, among many others, and appears on numerous CDs playing clarinets and various electronic and natural sounds.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/3ZosukkjTjk&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=3ZosukkjTjk&quot;&gt;New York-Paris-Berlin Live Nightingale Concert performed virtually under quarantine.&lt;/a&gt; More videos  &lt;a href=&quot;https://www.youtube.com/user/whybirdssing/videos&quot;&gt; here &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This event is free and open to all.  &lt;a href=&quot;https://universityofsussex.zoom.us/meeting/register/tJIpd-qqpjgoGten8-CZjawu5JEKJNl4eG5c&quot;&gt;Register in advance for this meeting.&lt;/a&gt;
After registering, you will receive a confirmation email containing information about joining the meeting.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;www.davidrothenberg.net&quot;&gt;www.davidrothenberg.net&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;www.nightingalesinberlin.com&quot;&gt;www.nightingalesinberlin.com&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://www.youtube.com/user/whybirdssing/videos&quot;&gt;www.youtube.com/user/whybirdssing/&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;div class=&quot;video-responsive&quot;&gt;
    &lt;iframe width=&quot;840&quot; height=&quot;3000&quot; src=&quot;https://universityofsussex.zoom.us/rec/share/pv53HZzXqTJLE4nGt27_fIwFBdi9aaa81HRI86IJyE4qYivLlLMKdV2QchEvqwDZ?startTime=1588863984000&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
        <pubDate>Fri, 01 May 2020 00:00:00 +0100</pubDate>
        <link>http://www.emutelab.org/blog/Rothenberg</link>
        <guid isPermaLink="true">http://www.emutelab.org/blog/Rothenberg</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>practice</category>
        
        <category>philosophy</category>
        
        <category>ecoacoustics</category>
        
        <category>improvisation</category>
        
        <category>multi-species music</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Materialities symposium</title>
        <description>&lt;p&gt;&lt;img src=&quot;/img/emutemat.jpg&quot; alt=&quot;emutemat&quot; /&gt;&lt;/p&gt;

&lt;h1&gt;Materialities symposium&lt;/h1&gt;

&lt;p&gt;Join us on the morning of Thursday 5th of December, 2019 for a fast-paced symposium on the subject of materialities in music making.&lt;/p&gt;

&lt;p&gt;We have two great workshops/presentations followed by a panel discussion around notions of the influence of materiality on music and sound making.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Workshops/Presentations&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://trsound.bandcamp.com/&quot;&gt;Tom Richards&lt;/a&gt; will present a workshop which invites participants to utilise his Voltage Controlled Turntables with some modular synthesiser equipment. Imagine scratching a record with LFO control, or changing pitch. 
Participants are encouraged to bring vinyl records to this session.&lt;/p&gt;

&lt;p&gt;Tom Richards is a musician, sound designer, artist, researcher and instrument maker, working in London UK. He has performed and exhibited widely in the UK, as well as internationally in the US, Germany, Peru, Singapore, Hungary, Japan and Sweden. Selected works and live performances have taken place at Tate Britain, The Queen Elizabeth Hall, The Science Museum, Spike Island, Cafe Oto, MK Gallery, Focal Point, and Camden Arts Centre. He has recently finished his PhD (Goldsmiths/Science Museum) on the work of Daphne Oram: electronic music pioneer, and founder member of the BBC Radiophonic Workshop. This research included the construction of Oram’s Mini Oramics synthesizer design (Circa 1975), a project that has since gained worldwide attention. He is represented by Nonclassical.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;&lt;a href=&quot;http://grrrr.org/&quot;&gt;Thomas Grill&lt;/a&gt;&lt;/b&gt; and &lt;b&gt;&lt;a href=&quot;http://tai-studio.org/&quot;&gt;Till Bovermann&lt;/a&gt;&lt;/b&gt; present activities relating to the &lt;b&gt;&lt;a href=&quot;https://rottingsounds.org/&quot;&gt;Rotting Sounds project&lt;/a&gt;&lt;/b&gt;. Here degradation in digital systems will be explored and discussed. 
Thomas Grill (University of Music and Performing Arts Vienna) is the project manager and principal investigator. He has ample experience in both scientific and artistic research and has been composing, performing and exhibiting with digital sound for over 20 years.
Till Bovermann (University of Applied Arts Vienna) is his main discourse partner. In his artistic works, Till addresses the relationship between seemingly contradictory elements, e.g., the digital and physical realm.
&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Round table/panel discussion - notions of materiality and influence on practice&lt;/b&gt;
As the final event in the symposium, topics relating to notions of materiality and influence on practice are discussed by a panel of academics/composers and performers. This promises to be a lively debate relating to media archeology, liveness and audience perspective.&lt;/p&gt;

&lt;p&gt;Evelyn Ficarra, Senior Lecturer in Music  &lt;a href=&quot;http://www.sussex.ac.uk/profiles/41192&quot;&gt;http://www.sussex.ac.uk/profiles/41192&lt;/a&gt;&lt;br /&gt;
Tom Richards&lt;br /&gt;
Till Bovermann&lt;br /&gt;
Thomas Grill&lt;br /&gt;
Further panel members and chair (TBC)&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.eventbrite.co.uk/e/materialities-emute-lab-music-symposium-tickets-82606421029&quot;&gt;Event registration page&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;NOTE:
This event follows the live EMUTE LAB 5: Materialities gig at The Rose Hill on the 4th of December. Details here: 
http://www.emutelab.org/blog/emutelab5
https://www.facebook.com/events/720543615076362&lt;/p&gt;

&lt;p&gt;See also:
&lt;a href=&quot;http://www.emutelab.org/blog/emutelab5&quot;&gt;http://www.emutelab.org/blog/emutelab5&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;The Rose Hill 4th December 2019, doors 7:30&lt;/b&gt;
£6 / £4&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Advance tickets:&lt;/b&gt; &lt;a href=&quot;https://www.eventbrite.co.uk/e/emute-labs-5-materialities-tickets-80358270751?fbclid=IwAR24wQuZiU43zIYNhlPd3hE5FU0fPazCZfJV3cSZxK5kPK-2F-UcS1pKh2I&quot;&gt;https://www.eventbrite.co.uk/e/emute-labs-5-materialities-tickets-80358270751?fbclid=IwAR24wQuZiU43zIYNhlPd3hE5FU0fPazCZfJV3cSZxK5kPK-2F-UcS1pKh2I&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;@emutelab&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.therosehill.co.uk&quot;&gt;https://www.therosehill.co.uk&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.facebook.com/events/720543615076362&quot;&gt;https://www.facebook.com/events/720543615076362&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate>
        <link>http://www.emutelab.org/blog/materialities</link>
        <guid isPermaLink="true">http://www.emutelab.org/blog/materialities</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>experimental</category>
        
        <category>materialities</category>
        
        <category>lathe cutting</category>
        
        <category>vinyl</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Emute Lab 5 @ The Rose Hill</title>
        <description>&lt;p&gt;&lt;img src=&quot;/img/emutelab5.jpg&quot; alt=&quot;EmuteLab5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Emute Lab presents: Materialities (04/12/19)&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;An evening of experimental music celebrating materialities in music making. From deceased instruments manipulated as digital fragments to turntables controlled by synthesisers, live record cutting and electronics.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Artists:&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Rotting Sounds&lt;/b&gt; &lt;a href=&quot;http://rottingsounds.org&quot;&gt;http://rottingsounds.org&lt;/a&gt;
&lt;br /&gt;Two solo performances joined under the Rotting Sounds project and by a common theme.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/AnnTJvAejzo&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;b&gt;Thomas Grill: Musical material&lt;/b&gt;
&lt;br /&gt;Probing of fragments of deceased instruments by use of digital sound.Sounding the materials, shapes, resonances – tracing remnants of a musical life.
&lt;br /&gt;
&lt;a href=&quot;http://grrrr.org&quot;&gt;http://grrrr.org&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AND&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Till Bovermann: Buffer manipulations&lt;/b&gt;&lt;br /&gt;
Probing and fragmentation of deceased digital sound.
Sounding the materials, shapes, resonances – tracing remnants of a brief ephemerality.&lt;br /&gt;
&lt;a href=&quot;http://lfsaw.de&quot;&gt;http://lfsaw.de&lt;/a&gt;
&lt;a href=&quot;https://lfsaw.bandcamp.com/album/re-interpretation&quot;&gt;https://lfsaw.bandcamp.com/album/re-interpretation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Tom Richards: Voltage controlled turntables and electronics&lt;/b&gt;&lt;br /&gt;
Performing with modified turntables and synthesisers&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://trsound.bandcamp.com/&quot;&gt;https://trsound.bandcamp.com/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Tom Richards is a musician, sound designer, artist, researcher and instrument maker, working in London UK. He has been working between sonic art, sculpture, film and music since graduating with an MA in Fine Art from Chelsea College of Art in 2004. Richards has built his own idiosyncratic modular electronic music system, with which he creates slowly evolving and heavily textured polyrhythmic improvisations. He has performed and exhibited widely in the UK, as well as internationally in the US, Germany, Peru, Singapore, Hungary, Japan and Sweden.
Selected works and live performances have taken place at Tate Britain, The Queen Elizabeth Hall, The Science Museum, Spike Island, Cafe Oto, MK Gallery, Focal Point, and Camden Arts Centre. 
He has recently finished his PhD (Goldsmiths/Science Museum) on the work of Daphne Oram: electronic music pioneer, and founder member of the BBC Radiophonic Workshop. This research included the construction of Oram’s Mini &lt;a href=&quot;https://www.bbc.co.uk/news/technology-36651270&quot;&gt;Oramics synthesizer&lt;/a&gt; design (Circa 1975), a project that has since gained worldwide attention.
He is represented by &lt;a href=&quot;https://www.nonclassical.co.uk/music&quot;&gt;Nonclassical&lt;/a&gt;.&lt;/p&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/258282473?title=0&amp;amp;byline=0&amp;amp;portrait=0&quot; width=&quot;640&quot; height=&quot;360&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;
&lt;a href=&quot;https://vimeo.com/258282473&quot;&gt;Maximum Overdrive - Performance with Tom Richards&lt;/a&gt; from &lt;a href=&quot;https://vimeo.com/user40747262&quot;&gt;Tom Lock&lt;/a&gt; on &lt;a href=&quot;https://vimeo.com&quot;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Furrowed: Live record cutting and modular synthesiser&lt;/b&gt;&lt;br /&gt;
New alias and project of Emute member Dylan Beattie. By using a record lathe and electronics a sound world is built around the material properties of live cut vinyl records.  &lt;br /&gt;
&lt;a href=&quot;http://furrowedsound.co.uk/&quot;&gt;http://furrowedsound.co.uk/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/db.jpg&quot; alt=&quot;Furrowedimage&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;
&lt;b&gt;The Rose Hill 4th December 2019, doors 7:30&lt;/b&gt;
£6 / £4&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Advance tickets:&lt;/b&gt; &lt;a href=&quot;https://www.eventbrite.co.uk/e/emute-labs-5-materialities-tickets-80358270751?fbclid=IwAR24wQuZiU43zIYNhlPd3hE5FU0fPazCZfJV3cSZxK5kPK-2F-UcS1pKh2I&quot;&gt;https://www.eventbrite.co.uk/e/emute-labs-5-materialities-tickets-80358270751?fbclid=IwAR24wQuZiU43zIYNhlPd3hE5FU0fPazCZfJV3cSZxK5kPK-2F-UcS1pKh2I&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;@emutelab&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.therosehill.co.uk&quot;&gt;https://www.therosehill.co.uk&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.facebook.com/events/720543615076362&quot;&gt;https://www.facebook.com/events/720543615076362&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 11 Nov 2019 00:00:00 +0000</pubDate>
        <link>http://www.emutelab.org/blog/emutelab5</link>
        <guid isPermaLink="true">http://www.emutelab.org/blog/emutelab5</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>experimental</category>
        
        <category>materialities</category>
        
        <category>lathe cutting</category>
        
        <category>vinyl</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>What&#39;s Happening in the World of Feedback Instruments?</title>
        <description>&lt;p&gt;At Emute Lab, several of our members have been concentrating their research efforts on building and performing with feedback instruments. You could define a Feedback Instrument as an instrument whose behaviour depends on the circulation of signals, and manipulation of the way in which these signals circulate around the instrument.  These instruments could be acoustic, electronic, digital, or hybrid.  Feedback will be the core of how they make sound and/or how musicians interact with them.&lt;/p&gt;

&lt;p&gt;There’s a great deal of activity in this area around the world at the moment, and here, I will attempt to highlight some of the recent developments in feedback instrument design and musicianship.  But before leaping into current work, let’s take a look at some past instruments and pieces that have had a big influence on today’s developments.&lt;/p&gt;

&lt;h4 id=&quot;eliane-radigue-usral&quot;&gt;Eliane Radigue: Usral&lt;/h4&gt;

&lt;p&gt;This is from Radigue’s collection of early feedback works.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/C_3Fu8YfSdI?start=684&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h4 id=&quot;max-neuhaus-fontana-mix-feed&quot;&gt;Max Neuhaus: &lt;a href=&quot;http://brainwashed.com/index.php?option=com_content&amp;amp;view=article&amp;amp;id=2399%3Amax-neuhaus-qfontana-mix-feed-six-realizations-of-john-cageq&amp;amp;catid=13%3Aalbums-and-singles&amp;amp;Itemid=1&quot;&gt;Fontana Mix-Feed&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;This piece uses contact microphone-speaker feedback through tympanis.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/x-cLk7TZuNY&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h4 id=&quot;alvin-lucier-bird-and-person-dyning&quot;&gt;Alvin Lucier: &lt;a href=&quot;http://www.alvin-lucier-film.com/bird.html&quot;&gt;Bird and Person Dyning&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;Speaker-binaural headphone feedback.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/6jLYof8sU4s&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h4 id=&quot;nicolas-collins-pea-soup&quot;&gt;Nicolas Collins: &lt;a href=&quot;https://www.nicolascollins.com/aboutpeasoup.htm&quot;&gt;Pea Soup&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;This piece uses shifting microphone-room feedback. Originally created in 1974, but here’s a newer revision from 2010.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/W7f5Iha7JyQ&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h4 id=&quot;david-tudor-neural-network-plus&quot;&gt;David Tudor: &lt;a href=&quot;http://www.lovely.com/albumnotes/notes1602.html&quot;&gt;Neural Network Plus&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;Feedback was a key part of Tudors compositions and installations.  This piece from the early 90s was created using repurposed neuromorphic hardware, which enables the creation of highly complex analog feedback systems.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/OyzeqA9-DiI&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;In Emute Lab, feedback instruments take a variety of forms.  Halldór Úlfarsson is the designer of the &lt;a href=&quot;https://www.halldorophone.info&quot;&gt;Halldorophone&lt;/a&gt;, and a growing family of new instruments that are descendents of his design. This family of string instruments use inbuilt speakers and exciters, together with individual string pickups and external processing to create a feedback loop. Halldór is researching his PhD in Emute Lab, and has recently developed two new instruments: The Sisters.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.halldorophone.info/public/img/2018-Square.jpg&quot; alt=&quot;Sister 1&quot; /&gt;
&lt;img src=&quot;https://www.halldorophone.info/public/img/2018-Standing.png&quot; alt=&quot;Sister 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is an early Halldorophone from 2009, played by Hildur Guðnadóttir.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/uo4Jq-_tysc&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Hildur plays the Halldorophone on several film soundtracks, including the Chernobyl soundtrack, for which she recently won an Emmy award.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/qcEPbx_iSjw&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;This video shows a Halldorophone-DIMA-A duet. Composition by Johan Svensson, performed by My Hellgren and Jari Suominen&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/DKJvAIadFWE&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Alice Eldridge and I collaborated with Halldór to develop the &lt;a href=&quot;https://www.feedbackcell.info/&quot;&gt;Feedback Cello&lt;/a&gt;.  These instruments are based in the Halldorophone design, as augmentations (and/or invasions) of the traditional acoustic cello.  They have a speaker mounted in the back of the cello.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/feedback_cello_speaker.jpg&quot; alt=&quot;Feedback Cello Speaker&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We have built two of these instruments, with different augmentations.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/feedback_cellos2.jpg&quot; alt=&quot;Feedback Cello Speaker&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here’s Alice playing at Fete Quaqua from 2016&lt;/p&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/180304450&quot; width=&quot;640&quot; height=&quot;360&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Here is a recording of a Feedback Cell performance from 2017, using the two cellos.&lt;/p&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/363528685&quot; width=&quot;640&quot; height=&quot;361&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Halldór is exploring augmentation of acoustic instruments further, developing a feedback double bass with &lt;a href=&quot;http://thanospl.net/?p=620&quot;&gt;Thanos Polymeneas-Liontiris&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/thanos_fbdbass.jpg&quot; alt=&quot;Feedback Double Bass&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The above three instruments, together with &lt;a href=&quot;http://www.ixi-audio.net/&quot;&gt;Thor Magnusson&lt;/a&gt; on Threnoscope, form &lt;a href=&quot;https://www.emutelab.org/braindeadensemble/&quot;&gt;Brain Dead Ensemble&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/bdeRoseHill2.jpg&quot; alt=&quot;Brain Dead Ensemble, Live at The Rose Hill, Brighton&quot; /&gt;
You could call this a ‘feedback ensemble’, as the Threnoscope is connected to all of the instruments, and the instruments affect each other acoustically during performance. This is their album ‘EFZ’.&lt;/p&gt;

&lt;iframe src=&quot;https://open.spotify.com/embed/artist/54rJ3o7aXEg9bzQ3MukIYh&quot; width=&quot;300&quot; height=&quot;380&quot; frameborder=&quot;0&quot; allowtransparency=&quot;true&quot; allow=&quot;encrypted-media&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Halldór has also developed a &lt;a href=&quot;http://halldor.gr/spetson/2019/07/01/fbdb.html&quot;&gt;Feedback Double Bass with Adam Pultz&lt;/a&gt;, this time invasively with a mounted speaker.&lt;/p&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/345985776&quot; width=&quot;640&quot; height=&quot;360&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Emute Lab member Joe Watson explores nested feedback networks and modular synthesis, ‘The Thing Breathed’.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/H8LlbtgdB5M&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;You can read some more about this and brain dead ensemble in the &lt;a href=&quot;https://live-interfaces.github.io/2018/ICLI2018.pdf&quot;&gt;ICLI 2018 proceedings&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Moving outside of Emute Lab, here are some more instruments based on the feedback principle.&lt;/p&gt;

&lt;p&gt;Tom Davis and Laura Reid: The Feral Cello.  This instrument has an exciter and pickup, that runs through DSP processing in a duet between cellist and laptopist.&lt;/p&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/237465790&quot; width=&quot;640&quot; height=&quot;360&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;This is Dan Overholt’s &lt;a href=&quot;https://vimeo.com/26661494?fbclid=IwAR0Qb5aAAhpIB9ZggqdsoVot8x6lcgg1qx-gkWYbbobGkdY_SfIyGdyBE4M&quot;&gt;Overtone Fiddle&lt;/a&gt;. Dan says: ‘This performance uses feedback via DSP filter-banks, set up to emulate an extra bank of resonant strings (simulating to some extent, the “hardanger fiddle” setup but with variable/extended feedback resonances).’&lt;/p&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/26766506&quot; width=&quot;640&quot; height=&quot;360&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;This is the Feedback Lapsteel, by Jiffer Harriman.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/79R6oaVdmnk&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;a href=&quot;http://www.ijin.no/feedbacker.htm&quot;&gt;Christian Blandhoel&lt;/a&gt; is a Norwegian noise musician, who has created a expansive range of &lt;a href=&quot;https://drive.google.com/file/d/1b7nw3aEj_tvvPHM-qRB1R8qVTUiyPNyF/view&quot;&gt;Feedbackers&lt;/a&gt;.  Here’s a video of one of them, and more on his youtube channel.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/lHq_7MlIeFY&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Luigi Marino: Cymbals with a handheld feedback device (containing a contact mic and exciter).&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/SaToWLbI-UA?start=962&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;This video shows a concert with two feedback instruments.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://tai-studio.org/portfolio/half-closed-loop.html&quot;&gt;Half-closed Loop&lt;/a&gt; by Till Boverman (from the beginning). This is custom-designed, using a brass pipe, wooden board with exciters and microphones.  In the second half (from 11:50) we move into feedback brass, with Ingi Garðar Erlendsson playing the &lt;a href=&quot;http://thrainnhjalmarsson.info/&quot;&gt;Thranaphone #2&lt;/a&gt;, a feedback tuba (with Eiríkur Orri Ólafsson playing Trumpet).  This instrument has a speaker mounted in the tuba and a mouthpiece microphone; the signal is processed through guitar pedals.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/l5vDKEZsJjY?start=0&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Jeff Snyder’s Feedback Trombone runs on a similar principle:&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/yT6Vq9jGC7w&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;a href=&quot;http://lesleyflanigan.com/&quot;&gt;Lesley Flanigan&lt;/a&gt; uses custom-instruments based around microphone-speaker feedback.  This is a concert from the Guggenheim Museum, New York from 2014.&lt;/p&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/122308468&quot; width=&quot;640&quot; height=&quot;360&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;There are also some great software instruments out there.  Tom Mudd uses a network of interacting chaotic oscillators in Gutter Synthesis.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/Y1qQd4DVIR4&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;a href=&quot;https://dariosanfilippo.tumblr.com/&quot;&gt;Dario Sanfilippo&lt;/a&gt; specialises in music generated from complex adaptive feedback systems; this is a performance of ‘Single-Fader Versitility’.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/hIrqmDif5uQ&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;In audio-visual feedback systems, there’s a cross-modal flow between sound and image.   This is Mick Grierson with a live performance of ‘Stench’.&lt;/p&gt;

&lt;video muted=&quot;&quot; controls=&quot;&quot;&gt;
    &lt;source src=&quot;/img/StenchGig.mp4&quot; type=&quot;video/mp4&quot; /&gt;
&lt;/video&gt;

&lt;p&gt;These are some highlights of contemporary feedback instruments, which take a range of forms. These instruments can be challenging but also extremely rewarding to play. The challenges come from dealing with the complexity of highly sensitive dynamical systems, and changing from conventional modes of instrumental control to shared agency with the instrument.  The rewards are to break into new sonic territories and to discover some radically new ways of playing music.&lt;/p&gt;
</description>
        <pubDate>Mon, 07 Oct 2019 00:00:00 +0100</pubDate>
        <link>http://www.emutelab.org/blog/feedback_insts</link>
        <guid isPermaLink="true">http://www.emutelab.org/blog/feedback_insts</guid>
        
        <category>emutelab</category>
        
        <category>feedback</category>
        
        <category>halldorophone</category>
        
        <category>cello</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Emute Lab 4 @ The Rose Hill</title>
        <description>&lt;p&gt;&lt;img src=&quot;/img/emutelab4.jpg&quot; alt=&quot;EMuTeLab2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Emute Lab presents: musically intelligent machines&lt;/p&gt;

&lt;p&gt;Emute Lab 4: Musically Intelligent Machines&lt;/p&gt;

&lt;p&gt;Come and hear new music created by musicians in collaboration with artificially intelligent machines.&lt;/p&gt;

&lt;p&gt;Expect some weird and wonderful experiments with new sounds and new musical instruments.&lt;/p&gt;

&lt;p&gt;Artists:&lt;/p&gt;

&lt;p&gt;MARIJE BAALMAN: gestural live coding&lt;/p&gt;

&lt;p&gt;MNISTREL: Live coding and uncanny interfaces&lt;/p&gt;

&lt;p&gt;SHELLY KNOTTS&lt;/p&gt;

&lt;p&gt;ANUZAK&lt;/p&gt;

&lt;p&gt;EVERYSONGIOWN: A Quantity Approach to Music Making&lt;/p&gt;

&lt;p&gt;and more artists who will be performing pieces made at our summer AI and music workshop&lt;/p&gt;

&lt;p&gt;The Rose Hill
£6 / £4
Advance tickets: &lt;a href=&quot;https://bit.ly/2JbzYXn&quot;&gt;https://bit.ly/2JbzYXn&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;@emutelab&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.mimicproject.com&quot;&gt;https://www.mimicproject.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.therosehill.co.uk&quot;&gt;https://www.therosehill.co.uk&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.facebook.com/events/936387710040807/&quot;&gt;https://www.facebook.com/events/936387710040807/&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 26 Jun 2019 00:00:00 +0100</pubDate>
        <link>http://www.emutelab.org/blog/emutelab4</link>
        <guid isPermaLink="true">http://www.emutelab.org/blog/emutelab4</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>improvisation</category>
        
        <category>audiovisual</category>
        
        <category>AI</category>
        
        <category>machine learning</category>
        
        <category>MIMIC</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>MIMIC Artist Summer Workshop</title>
        <description>&lt;p&gt;&lt;strong&gt;:::: Week starting July 22nd, 9am-5pm, @ The SHL, Sussex University ::::&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Interested in Music and AI? MIMIC is a research project that implements machine learning and machine listening in a live coding environment for creative coders. We have recently released our tools on &lt;a href=&quot;http://www.mimicproject.com&quot;&gt;mimicproject.com&lt;/a&gt; and are in the process of finalising our system for creating live coding languages for creative AI.&lt;/p&gt;

&lt;p&gt;For this summer workshop in sunny Brighton, we invite artists who are interested in using machine learning and machine listening in their live performances and composition to build their own live coding languages with our new &lt;em&gt;Sema&lt;/em&gt; system. Participants will be able to use the workshop to develop and further their own projects, and in turn we will benefit from user-testing and collaborative developments. Some fundamental programming skills are required, but certainly not at a professional level. This workshop is not about learning how to live code, but rather about how to make your own live coding system in our simple and user-friendly system. Everyone is welcome who is passionate about the future of live coding.&lt;/p&gt;

&lt;p&gt;This workshop residency will start on the week commencing July 22nd and last for five days. The workshop will take place in combination with longer artist residencies with Marije Baalman and Enrike Hurtado who will work on their respective choreographic coding and digital txalaparta projects.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Week Programme:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Monday - July 22nd&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;9am - Introduction to MIMIC and the workshop
10am - Workshop in the Sema playground for language design
11am - 10 min demo + project development
1pm - Lunch
2pm - Workshop in Machine Learning
4pm - 10 min demo + project development
5pm - Work in progress demo of artists-in-residence’s projects
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Tuesday - July 23rd&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;9am - 10 min demo + project development
10am - Counterpoint presentation (https://ctpt.co)
11am - Counterpoint workshop (Tero Parviainen and Samuel Diggins)
1pm - Lunch
2pm - 10 min demo + project development
4pm - Presentation of project ideas and sketches
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Wednesday - July 24th&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;9am - Project development
10am - Workshop in machine listening
11am - 10 min demo + project development
1pm - Lunch
2pm - Project development
3pm - Discussion of problems that have emerged
4pm - Project development
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Thursday - July 25th&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;9am - 10 min demo + project development
10am - (Aesth)et(h)ics and creative-AI
1pm - Lunch
2pm - Project development
5pm - Sound check
7pm - Concert with works at the Rose Hill Pub
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Friday - July 26th&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;10am - Coffee and discussion of gig
11am - Wrapping up projects
1pm - Lunch w. a bid sprint
2pm - Project showcases with Enrike Hurtado and Marije Baalman
3pm - Participant demos
4pm - Discussion about Sema (experience, requests, future path)
5pm - Beer in the sun
8pm - Dinner in town
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We have published a call for proposals &lt;a href=&quot;https://forms.gle/gYBHKBRrsokn3SjQ6&quot;&gt;HERE&lt;/a&gt; for people interested in participating in the workshop. We have funds to support travel and accommodation for six-ten people from Europe and we will seek to provide lunch and coffee out in the lovely lab garden throughout the week. We are especially interested in receiving applications from as diverse group as possible.&lt;/p&gt;

&lt;p&gt;We will be assessing the applications on Monday morning on July 1st, so the deadline is 9am GMT.&lt;/p&gt;

&lt;p&gt;See you in the lab, in July!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/SHL.png&quot; alt=&quot;Digital Humanities lab&quot; /&gt;
&lt;em&gt;A picture of the lab where the workshop will take place - note the lovely garden!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/Marije.jpg&quot; alt=&quot;Artist-in-residence Marije&quot; /&gt;
&lt;em&gt;Artist-in-residence Marije Baalman working on gestural live coding language design!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/Enrike.jpg&quot; alt=&quot;Artist-in-residence Enrike&quot; /&gt;
&lt;em&gt;Artist-in-residence Enrike Hurtado working on machine learning for the txalaparta instrument&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/MIMICworkshop.jpg&quot; alt=&quot;Workshop&quot; /&gt;
&lt;em&gt;And this is how it looked&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 24 May 2019 00:00:00 +0100</pubDate>
        <link>http://www.emutelab.org/blog/summerworkshop</link>
        <guid isPermaLink="true">http://www.emutelab.org/blog/summerworkshop</guid>
        
        <category>emutelab</category>
        
        <category>workhop</category>
        
        <category>live coding</category>
        
        <category>language design</category>
        
        <category>summer</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>MIMIC platform for Machine Learning and Machine Listening</title>
        <description>&lt;p&gt;MIMIC is a web platform for the artistic exploration of musical machine learning and machine listening. We have designed this collaborative platform as an interactive online coding environment, engineered to bring new technologies in AI and signal processing to artists, composers, musicians and performers all over the world.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;http://www.mimicproject.com&quot;&gt;MIMIC platform&lt;/a&gt; has a built-in audio engine, machine learning and machine listening tools that makes it easy for creative coders to get started using these techniques in their own artistic projects. The platform also includes various examples of how to integrate external machine learning systems for sound, music and art making. These examples can be forked and further developed by the users of the platform.&lt;/p&gt;

&lt;p&gt;Over the next three years, we aim to integrate brand new and developing creative systems into this platform so that they can be more easily used by musicians and artists in the creation of entirely new music, sound, and media, enabling people to understand and apply new computational techniques such as Machine Learning in their own creative work.&lt;/p&gt;

&lt;p&gt;MIMIC or “Musically Intelligent Machines Interacting Creatively” is a three year AHRC-funded project, run by teams at Goldsmiths College, Durham University and the University of Sussex.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/MIMIC.png&quot; alt=&quot;MIMIC&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 16 May 2019 00:00:00 +0100</pubDate>
        <link>http://www.emutelab.org/blog/mimic</link>
        <guid isPermaLink="true">http://www.emutelab.org/blog/mimic</guid>
        
        <category>emutelab</category>
        
        <category>workhop</category>
        
        <category>live coding</category>
        
        <category>JavaScript</category>
        
        <category>language design</category>
        
        <category>summer</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Creative Audio Coding Evening</title>
        <description>&lt;p&gt;&lt;strong&gt;:::: Thursday, May 9th, 5.30-7.30pm, @ The SHL, Sussex University ::::&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;During the next academic year, the Emute Lab will collaborate with the Sussex Humanities Lab in running monthly “Creative Audio Coding” evenings in the SHL. This will be a space for people to come and work on their sound and music projects, but we will also introduce selected technologies (such as new software and languages) or techniques (such as synthesis techniques, embodied control or machine learning) in each session. In this teaser on May 9th, we will start with the very popular and powerful &lt;a href=&quot;https://supercollider.github.io&quot;&gt;SuperCollider&lt;/a&gt; audio programming language. This system has been instrumental in establishing the practice of &lt;a href=&quot;http://www.toplap.org&quot;&gt;live coding&lt;/a&gt; and has been the main environment for creative sound coding for over two decades.&lt;/p&gt;

&lt;p&gt;In this session Thor Magnusson will give a short introduction to SuperCollider, and his recently republished tutorial &lt;a href=&quot;https://leanpub.com/ScoringSound&quot;&gt;Scoring Sound: Creative Music Coding with SuperCollider&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We will bring some drinks and snack, but participants will have to bring their laptops and headphones. &lt;strong&gt;Everyone is welcome&lt;/strong&gt;, especially beginners and the curious, and we especially encourage people from outside the University of Sussex to join us in these sessions.&lt;/p&gt;

&lt;p&gt;See you in the lab.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/supercollider.png&quot; alt=&quot;SuperCollider&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 07 May 2019 00:00:00 +0100</pubDate>
        <link>http://www.emutelab.org/blog/creativeaudiocoding</link>
        <guid isPermaLink="true">http://www.emutelab.org/blog/creativeaudiocoding</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>programming</category>
        
        <category>coding</category>
        
        <category>live coding</category>
        
        <category>improvisation</category>
        
        <category>audiovisual</category>
        
        
        <category>blog</category>
        
      </item>
    
  </channel>
</rss>
