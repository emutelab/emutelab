<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Emute Lab</title>
    <description>A Music Informatics and Performance Technologies Lab based in the School of Media, Film and Music at the University of Sussex</description>
    <link>http://www.emutelab.org/</link>
    <atom:link href="http://www.emutelab.org/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Thu, 04 Jan 2018 09:48:36 +0000</pubDate>
    <lastBuildDate>Thu, 04 Jan 2018 09:48:36 +0000</lastBuildDate>
    <generator>Jekyll v3.1.6</generator>
    
      <item>
        <title>EMuTeLab 0: 7pm, 12 Jan 2018, The Rose Hill, Brighton</title>
        <description>&lt;p&gt;&lt;img src=&quot;/img/emutelab0_webflyer.png&quot; alt=&quot;EMuTeLab0 Gig Flyer&quot; /&gt;&lt;/p&gt;

&lt;p&gt;EMuTeLab presents…&lt;/p&gt;

&lt;p&gt;JesterN (Laser Drawing / Modular Synth)&lt;/p&gt;

&lt;p&gt;Marije Baalman (Chrysalis / Installations)&lt;/p&gt;

&lt;p&gt;Brain Dead Ensemble (Threnascope / Feedback Cellos / Feedback Double Bass)&lt;/p&gt;

&lt;p&gt;7pm, 12 Jan 2018, The Rose Hill, Brighton. £5&lt;/p&gt;

&lt;p&gt;====== JesterN: Laser Drawing&lt;/p&gt;

&lt;p&gt;JesterN’s Laser Drawing is a synesthetic experience in which you can listen to what you see, and see what you listen to
Using its modular synthesizer, JesterN manipulates electric voltages live, sending them in exactly the same way to the speakers to create sound and to the laser to create its curvy shapes with vivid colors. An artisanal live show in which every beat and every shape is simultaneously improvised on the stage. Being cooked on the spot, music-wise it depends on the space and on the vibe: it can go from drones, to harsh noise, from techno straight beats to IDM syncopations, or something completely diferent …&lt;/p&gt;

&lt;p&gt;Alberto Novello a.k.a. JesterN is a scientist, composer, sound and video artist. In his works, he has assisted Alvin Lucier, Nicholas Collins and Trevor Wishart. His artistic works have been presented in international festivals such as Amsterdam Dance Event, Venice Biennale, Impuls Tanz Vienna, Seoul International Music Festival, Emu Fest Roma, Monaco Electroacoustique, New York Computer Music Festival, Rewire Festival and conferences such as NIME, ICMC, ISMIR, ICMPC, ICA, ICCE and ESSEM and institutes for contemporary music research such as CCMAS in Mexico, GRM in France, Logos Foundation in Belgium, STEIM Amsterdam, IEM Graz, OMI New York, the Royal Conservatory of Den Haag, Conservatory of Padua.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.jestern.com/&quot;&gt;http://www.jestern.com/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;====== Marije Baalman:&lt;/p&gt;

&lt;p&gt;A cocoon lies on stage, barely recognisable in the dim light. Slow tones are sounding in the space. The light seems to change color – the tones are changing slowly in pitch. The cocoon seems to move – the light seems to get brighter and gradually shift color. Suddenly a fast movement – a shrieking sound fills the space – then again everything quiets down – the movement, the sound, the light.&lt;/p&gt;

&lt;p&gt;Chrysalis is a performative environment where the focus is on slow movements – becoming aware of the minimal movements of the body, both conscious and unconscious movements. It is about interaction on a long timescale – involving multiple senses (hearing, sight, haptic).&lt;/p&gt;

&lt;p&gt;Marije Baalman is an artist and researcher/developer working in the field of interactive sound art.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.marijebaalman.eu/&quot;&gt;https://www.marijebaalman.eu/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;====== Brain Dead Ensemble:&lt;/p&gt;

&lt;p&gt;Thor Magnusson (Threnascope, &lt;a href=&quot;http://www.ixi-audio.net/&quot;&gt;http://www.ixi-audio.net/&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Thanos Polymeneas Liontiris (Feedback Bass, &lt;a href=&quot;http://thanospl.net/&quot;&gt;http://thanospl.net/&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Alice Eldridge&lt;/p&gt;

&lt;p&gt;Chris Kiefer&lt;/p&gt;

&lt;p&gt;(Feedback Cell, Feedback Cellos, &lt;a href=&quot;http://feedbackcell.ooo/&quot;&gt;http://feedbackcell.ooo/&lt;/a&gt;)&lt;/p&gt;
</description>
        <pubDate>Thu, 04 Jan 2018 00:00:00 +0000</pubDate>
        <link>http://www.emutelab.org/blog/emutelab0</link>
        <guid isPermaLink="true">http://www.emutelab.org/blog/emutelab0</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>performances</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Emute Lab in 2017</title>
        <description>&lt;p&gt;The Experimental Music Technology Lab has had a busy year in 2017. Some of the key events are listed below:&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Performances&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Algorave Brighton&lt;/b&gt; - September 7th. The Emute Lab co-organised an &lt;a href=&quot;https://algorave.com&quot;&gt;Algorave&lt;/a&gt; hosted by the British Science Festival. Performances with Algobabes, Slub, Renick Bell, Chris Kiefer and Thor Magnusson. See information &lt;a href=&quot;https://www.britishsciencefestival.org/event/algorave/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Luuma @ London Algorave&lt;/b&gt;&lt;br /&gt;
Chris Kiefer performing at the &lt;a href=&quot;https://algorave.com/london/&quot;&gt;London Algorave&lt;/a&gt; in June.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Syncphonia ‘Orchestra Hero’ event at the British Science Festival&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Thor Magnusson at Borealis&lt;/b&gt; &lt;br /&gt;
Threnoscope + Voluspa at the &lt;a href=&quot;http://www.borealisfestival.no/2017/threnoscope-thor-magnusson-2/&quot;&gt;Borealis Festival&lt;/a&gt; in Bergen, March.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Chevalier &amp;amp; Duff, 200.104.200.2,&lt;/b&gt; @ NIME 2017&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Feedback Cello Performances&lt;/b&gt; &lt;br /&gt;
At Bournemouth, Loop Berlin, HAL@SARC, NIME, Spirit of Gravity, Mengi, Algomech, DesInC&lt;br /&gt; see &lt;a href=&quot;http://feedbackcell.ooo/live/&quot;&gt;http://feedbackcell.ooo/live/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;O, One a 5 minute opera for two Nao Robots and cello&lt;/b&gt; &lt;br /&gt;
Words and music by Evelyn Ficarra, premiered at the Robot Opera Mini-Symposium on 15th June 2017. Performed by two Nao Robots (as themselves); Alice Eldridge (cello); directed /designed by Tim Hopkins; co-devised and programmed by Ron Chrisley. 
&lt;a href=&quot;http://www.sussex.ac.uk/cromt/archive/robotopera&quot;&gt;http://www.sussex.ac.uk/cromt/archive/robotopera&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Ficarra, Evelyn. Ghost Cup - a sound installation.&lt;/b&gt;&lt;br /&gt; 
Columbia University, April 7-8 2017, New York USA
&lt;a href=&quot;http://blogs.cuit.columbia.edu/reembodiedsound/&quot;&gt;http://blogs.cuit.columbia.edu/reembodiedsound/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Ficarra, Evelyn. Scores for objects and electronics with Heather Frasch&lt;/b&gt;&lt;br /&gt; 
Studio 8, 8th May 2017, Berlin.
&lt;a href=&quot;https://www.facebook.com/events/1473355456065457/&quot;&gt;https://www.facebook.com/events/1473355456065457/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Thanos Polymeneas Liontiris, ACCA, 13 February 2017&lt;/b&gt;
A Magnificent Crossbreeding of Protein and Tinplate&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;b&gt;Publications&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Bright, D. (2017) Conjuring the sonic ghosts of industrial and post-industrial spaces, in &lt;a href=&quot;http://www.cambridgescholars.com/the-post-industrial-landscape-as-site-for-creative-practice&quot;&gt;The Post-Industrial Landscape as Site for Creative Practice&lt;/a&gt;, Cambridge Scholars Publishing.&lt;/p&gt;

&lt;p&gt;Eldridge, Alice and Kiefer, Chris (2017) The self-resonating feedback cello: interfacing gestural and generative processes in improvised performance. New Interfaces for Music Expression. Download &lt;a href=&quot;http://homes.create.aau.dk/dano/nime17/papers/0005/paper0005.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Magnusson, Thor (2017) Musical Organics: A Heterarchical Approach to Digital Organology&lt;br /&gt;
in Journal of New Music Research. Download &lt;a href=&quot;http://www.tandfonline.com/doi/full/10.1080/09298215.2017.1353636&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Magnusson, Thor (2017) Contextualizing Musical Organics: An Ad-hoc Organological Classification Approach &lt;br /&gt;
NIME 2017 conference. Download &lt;a href=&quot;http://ixi-audio.net/thor/Magnusson_NIME2017_MusicalOrganics.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Webb, Sharon, Kiefer, Chris, Jackson, Ben, Baker, James and Eldridge, Alice (2017) Mining oral history collections using music information retrieval methods. Music Reference Services Quarterly. Download &lt;a href=&quot;http://www.tandfonline.com/doi/abs/10.1080/10588167.2017.1404307&quot;&gt; here&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;b&gt;Events&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Interdisciplinary perspectives: Machine Listening &amp;amp; Listening Machines&lt;/b&gt;&lt;br /&gt;
April 27-28. Sussex Humanities Lab, University of Sussex, Brighton&lt;br /&gt;
&lt;a href=&quot;http://www.algorithmiclistening.org/workshop1/ &quot;&gt;http://www.algorithmiclistening.org/workshop1/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Understanding Distributed Agency Between Listening Algorithms and Humans&lt;/b&gt;&lt;br /&gt;
May 31-June 1. Sonic Arts Research Centre, Queen’s University Belfast&lt;br /&gt;
&lt;a href=&quot;http://www.algorithmiclistening.org/workshop2/&quot;&gt;http://www.algorithmiclistening.org/workshop2/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Future Implications and Applications of Algorithmic Listening&lt;/b&gt;&lt;br /&gt;
Sept 14-15. University of Sussex, Brighton&lt;br /&gt;
&lt;a href=&quot;http://www.algorithmiclistening.org/workshop3/&quot;&gt;http://www.algorithmiclistening.org/workshop3/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Long table – Humanising Algorithmic Listening in Culture and Conservation&lt;/b&gt;&lt;br /&gt;
Sept 14th 20:00 as part of the 2017 Brighton Digital Festival&lt;br /&gt;
&lt;a href=&quot;http://brightondigitalfestival.co.uk/events/humanising-algorithmic-listening-culture-conservation &quot;&gt;http://brightondigitalfestival.co.uk/events/humanising-algorithmic-listening-culture-conservation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;DIY radio transmission – Pi Streambox Workshop&lt;/b&gt;&lt;br /&gt;
Oct 12th 14:00 and 18:30 as part of the Brighton Digital Festival &lt;br /&gt;
&lt;a href=&quot;http://brightondigitalfestival.co.uk/events/diy-radio-transmission-pi-streambox-workshop&quot;&gt;http://brightondigitalfestival.co.uk/events/diy-radio-transmission-pi-streambox-workshop&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Residency at CNMAT and CMC&lt;/b&gt;&lt;br /&gt;
In May, Thor Magnusson did a residency at CNMAT, Berkeley which included giving a lecture on current research. In June, he visited CMC, Columbia with the same programme. &lt;br /&gt;
Info &lt;a href=&quot;http://cnmat.berkeley.edu/projects/sonic-writing-research&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Marije Baalman residency at Sussex&lt;/b&gt;&lt;br /&gt;
Marije Baalman did a residency at Emute Lab collaborating with Chris Kiefer. This will be continued in January 2018, ending with a gig.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Forum for Augmented Reality Immersive Instruments (ARIMI)&lt;/b&gt;
Cecile Chevalier &amp;amp; Chris Kiefer in partnership with Kirk Woolford, June 19-20, 2017&lt;br /&gt; 
&lt;a href=&quot;http://users.sussex.ac.uk/~ad207/arimi/&quot;&gt;http://users.sussex.ac.uk/~ad207/arimi/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Emute Lab in Reykjavik&lt;/b&gt;&lt;br /&gt;
Alice Eldridge and Chris Kiefer did a residency at the Icelandic Arts Academy, also performing at &lt;a href=&quot;https://mengi.net/events/2017/10/28/feb12th&quot;&gt;Mengi&lt;/a&gt;, in Reykjavik.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Alberto Novello visiting researcher&lt;/b&gt;&lt;br /&gt;
Alberto Novello gave a &lt;a href=&quot;http://www.emutelab.org/blog/novello&quot;&gt;talk, workshop and tutorials&lt;/a&gt;. Talk title: Invisible to visible: bio signals and possible applications in the arts&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;b&gt;Conferences&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Evelyn Ficarra&lt;/b&gt; ‘The Sound Object in Theatrical and Installation Contexts’, Re-embodied Sound Conference, Columbia University, New York 8th April 2017
&lt;a href=&quot;http://blogs.cuit.columbia.edu/reembodiedsound/&quot;&gt;http://blogs.cuit.columbia.edu/reembodiedsound/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Alice Eldridge at a panel @ Loop 2017&lt;/b&gt;
Alice Eldridge on a panel on hybrid instruments at Ableton’s Festival of music, technology and creative practice - Loop, Berlin. &lt;br /&gt;
Alice and Chris Kiefer will also give a performance in the maker space. 
&lt;a href=&quot;https://loop.ableton.com/2017/program/activity/motors-magnets-and-motion-electronic-music-instruments-physical-world/&quot;&gt;Info here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Alice Eldridge and Danny Bright&lt;/b&gt; at Sound &amp;amp; Environment
Alice - Paper &amp;amp; Plenary Panel
Danny - Installation: Thrumming Halls
&lt;a href=&quot;http://www2.hull.ac.uk/fass/drama,-music-and-screen/conferences/sound--environment-2017.aspx&quot;&gt;http://www2.hull.ac.uk/fass/drama,-music-and-screen/conferences/sound–environment-2017.aspx&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Robot Opera Mini Symposium&lt;/b&gt;, organised by Evelyn Ficarra, featuring talks by Chris Kiefer, Ron Chrisley, Thanos Polymeneas-Liontiris, with brief introduction by Evelyn Ficarra ‘Why Robot Opera’. The day examined issues of embodiment, artificial intelligence and vocality through scholarly research and creative practice. 15 June 2017. 
&lt;a href=&quot;http://www.sussex.ac.uk/cromt/archive/robotopera&quot;&gt;http://www.sussex.ac.uk/cromt/archive/robotopera&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanos Polymeneas Liontiris, in The Operatic Symposium, University of Sussex, 19th May 2017, title:
The Operatic Bot&lt;/p&gt;

&lt;p&gt;Thanos Polymeneas Liontiris, in Robot Opera Symposium, University of Sussex, 17th June 2017, title:
Voices Without Bodies: The Operatic Bot in immersive performance&lt;/p&gt;

&lt;p&gt;Thanos Polymeneas Liontiris, in 6th International Scientific Meeting for Sound and Musical Instruments, Porto, August 2017, title:
Instrumented Spaces: Two Immersive Music Theatre Experiences&lt;/p&gt;

&lt;p&gt;Thanos Polymeneas Liontiris, in Annual Conference of Theatre and Performance Research Association (TaPRA), University of Salford, August 2017, title:
Cyber-Divas: Vocaloids as Postdigital Opera Singers&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;b&gt;Software&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Syncphonia - &lt;a href=&quot;http://www.syncphonia.co.uk/&quot;&gt;http://www.syncphonia.co.uk/&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;b&gt;Research grants&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://gtr.rcuk.ac.uk/projects?ref=AH%2FR002657%2F1&quot;&gt;MIMIC&lt;/a&gt; - Thor Magnusson and Chris Kiefer in collaboration with Goldsmiths and Durham University.&lt;/p&gt;

</description>
        <pubDate>Sun, 31 Dec 2017 00:00:00 +0000</pubDate>
        <link>http://www.emutelab.org/blog/year2017</link>
        <guid isPermaLink="true">http://www.emutelab.org/blog/year2017</guid>
        
        <category>emutelab</category>
        
        <category>eventa</category>
        
        <category>PhD</category>
        
        <category>NIME</category>
        
        <category>sonificiaton</category>
        
        <category>instruments</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Emute Lab PhD presentations</title>
        <description>&lt;p&gt;&lt;b&gt;:::: Monday, October 30th, 1.00pm @ SHL ::::&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;We have two new PhD researchers starting with us this autumn, Halldór Úlfarsson and Iain Emsley. During this 50 min lunch time talk we will have two 15 minute presenations and then dedicate 20 minutes to discuss these fresh and exciting research projects.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Halldór Úlfarsson&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Title: &lt;b&gt;Infiltrating History&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;What makes a musical instrument real? Is it real when music is being made on it or is it perhaps more real when it gets mentioned in a book or when it is placed in an archive for musical instruments; when it becomes history. I tell the tale of the halldorophone and how it graduated from being a postmodern joke to a musical instrument with something of an established culture of use. I consider if the halldorophone is actually a different object by now (or if the joke has just gotten better).&lt;/p&gt;

&lt;p&gt;Bio: &lt;a href=&quot;http://www.halldorulfarsson.info&quot;&gt;Halldór Úlfarsson&lt;/a&gt; (IS) has been working with musicians on projects involving his electro acoustic string instrument the halldorophone for about a decade. Compositions for the halldorophone have been featured in various genres of music in a variety of contexts (most recently Oscar winning Hollywood films). For the past five years Halldór has been at the Design Department of the Icelandic Academy of Art and part time lecturing in the Music Department in the same school. He is now pursuing a PhD at the Music Department at University of Sussex with Drs. Thor Magnusson and Chris Kiefer.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/violbulge.jpg&quot; alt=&quot;Violin&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;b&gt;Iain Emsley&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Title: &lt;b&gt;To sonify, or not to sonify&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;In between other projects, I experiment with sonification as a critical tool. In this presentation, I show some of my work with extracting parts of editorial structures of Shakespeare’s Hamlet, explore a software community, and traffic changes in national network. I present some of the models and the questions that were raised as ongoing work.&lt;/p&gt;

&lt;p&gt;Bio: Iain works a Research Associate at the Oxford e-Research Centre on digital libraries, software sustainability, and user interfaces for the museum visitors with visual impairments. Previous roles include working with the Square Kilometre Array, Janet and Forbidden Planet. He is studying for a PhD in Digital Media with Prof David Berry and Thor Magnusson.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/emsley.png&quot; alt=&quot;Emsley&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 24 Oct 2017 00:00:00 +0100</pubDate>
        <link>http://www.emutelab.org/blog/twophds</link>
        <guid isPermaLink="true">http://www.emutelab.org/blog/twophds</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>PhD</category>
        
        <category>NIME</category>
        
        <category>sonificiaton</category>
        
        <category>instruments</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Visiting Researcher: Alberto Novello</title>
        <description>&lt;p&gt;&lt;b&gt;:::: Thursday, October 26th, 1.00pm @ SHL ::::&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Our visiting researcher, Dr Alberto Novello, will give a talk at the Sussex Humanities Lab, followed by a short workshop. All welcome!&lt;/p&gt;

&lt;p&gt;Talk Title: &lt;b&gt;Invisible to visible: bio signals and possible applications in the arts.&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;In the lecture I will present my body of work, with a particular emphasis on the bio data installations and performances. I will talk about aesthetics of bio signal performances and the correlated dramaturgical limitations. I will explain the approach I followed when creating Fragmentation, UN (focussed) and Brain Pong: my three works using EEG signals. I will explain the techniques and mathematical tools I used and discuss/criticize the final results.&lt;/p&gt;

&lt;p&gt;After the lecture there will be a &lt;b&gt;workshop&lt;/b&gt; on the same topic, open to all:&lt;/p&gt;

&lt;p&gt;The focus of the workshop is to get first acquainted with the hardware: two EEG headsets will be compared in their level of complexity to setup vs quality of their data. The workshop will also talk about the possible alternatives on the market the pros and cons of the most common headsets around. The second part of the workshop will focus on software and data analysis: what kind of high-level features can we extract from the raw EEG data? How should we treat that data to extract for example energy bands? What do those band mean and how do they correlate with our everyday brain activity? In the third part, the participants will be encouraged to imagine a possible short performance/installation and, in groups, try and sketch a possible code for it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/novello.jpg&quot; alt=&quot;Novello&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Alberto Novello is a scientist, composer, sound and video artist. His main artistic focus is directed towards the creation of probabilistic multi-media architectures, on the technological limit between instability and error, failure and expression. Lately he moved from digital systems to analog found or decontextualized electronic ensembles.&lt;/p&gt;

&lt;p&gt;He graduated in Nuclear Physics at the University of Trieste, completed the master “Art, Science and Technologies” with Jean Claude Risset and Claude Cadoz, he obtained a PhD degree at the Technische Universiteit Eindhoven with Armin Kohlrausch and graduated in electroacoustic music composition at the Institute of Sonology, Royal Conservatory of Den Haag with Paul Berg, Joel Ryan, and Richard Barret. In his works, he has assisted Alvin Lucier, Nicholas Collins and Trevor Wishart. In the years he also worked Philips Research, Eindhoven, and Auro Technologies Belgium creating software for their audio application.&lt;/p&gt;

&lt;p&gt;His artistic works have been presented in international festivals such as Amsterdam Dance Event, Venice Biennale, Impuls Tanz Vienna, Seoul International Music Festival, Emu Fest Roma, Monaco Electroacoustique, New York Computer Music Festival, Rewire Festival and conferences such as NIME, ICMC, ISMIR, ICMPC, ICA, ICCE and ESSEM and institutes for contemporary music research such as CCMAS in Mexico, GRM in France, Logos Foundation in Belgium, STEIM Amsterdam, IEM Graz, OMI New York, the Royal Conservatory of Den Haag, Conservatory of Padua.&lt;/p&gt;

&lt;p&gt;He was part of the Sonology Electroacoustic Ensemble. He has released his works on CD/DVD as “JesterN’ for Dobialabel, Modisti, Bowindo, SONMA Archive and Hybrida records.&lt;/p&gt;

&lt;p&gt;Novello has improvised with Evan Parker and Butch Morris, Karl Berger and composed for the choreographies of Ola Maciejewska and Liat Waysbort.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;www.jestern.com&quot;&gt;www.jestern.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ALBERTO NOVELLO / JesterN&lt;br /&gt;
site: &lt;a href=&quot;www.jestern.com&quot;&gt;jestern.com&lt;/a&gt;&lt;br /&gt;
shop: &lt;a href=&quot;www.jestern.bandcamp.com&quot;&gt;jestern.bandcamp.com&lt;/a&gt;&lt;br /&gt;
audio: &lt;a href=&quot;www.soundcloud.com/jestern&quot;&gt;soundcloud.com/jestern&lt;/a&gt;&lt;br /&gt;
video: &lt;a href=&quot;www.vimeo.com/jestern&quot;&gt;vimeo.com/jestern&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 10 Oct 2017 00:00:00 +0100</pubDate>
        <link>http://www.emutelab.org/blog/novello</link>
        <guid isPermaLink="true">http://www.emutelab.org/blog/novello</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>machine learning</category>
        
        <category>analog synthesis</category>
        
        <category>brain interfaces</category>
        
        <category>laser</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Residency Report: Marije Baalman and Chrysalis</title>
        <description>&lt;p&gt;For the past six days, &lt;a href=&quot;https://www.marijebaalman.eu&quot;&gt;Marije Baalman&lt;/a&gt; has been visiting Sussex for part one of a residency with by EMuteLab and Sussex Humanities Lab.   We’ve been exploring serendipity in mappings for interactive instruments, and focusing on her recent piece &lt;a href=&quot;https://www.marijebaalman.eu/projects/chrysalis.html&quot;&gt;Chrysalis&lt;a&gt;.&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Chrysalis is a cocoon like instrument made from stretch fabric and poles. You crawl into the structure, and when you move around, the wireless accelerometers and stretch sensors (using Marije’s SenseStage system) are mapped to sound and to RGB lights which light up the chrysalis.  Marije wanted to explore new mappings which were less predictable and more engaging to interact with, while at the same time, did not risk moving into modes that were too random or out of keeping with the broad aesthetics of the piece.  Following from some of my &lt;a href=&quot;https://sro.sussex.ac.uk/51860/1/NIME2014-ESN.pdf&quot;&gt;previous work using Echo State Networks&lt;/a&gt; to create complex mappings, we explored Jaeger’s more recent innovations in this area, using a new technique: &lt;a href=&quot;http://minds.jacobs-university.de/conceptors&quot;&gt;Conceptors&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Conceptors essentially capture modes of behaviour of a reccurrent neural network, after which they can be used for pattern generation and for sequence recognition.  When used for pattern generation, they have some very interesting properties: you can mix and morph between patterns and also extrapolate new pattern variations.  This fitted in really well with our aim of encouraging interesting variation in mappings, while staying within a broader aesthetic.  Conceptors allow the creation of new and interesting pattern variations, but without moving too far from the original pattern. In other words, we can create surprises without the risk of them being too surprising.  The addition bonus is that these patterns are generated in real time, and can interact intuitively with sensors. We mapped them to control lighting patterns, and also used the network activations as wavetables to synthesise sound.&lt;/p&gt;

&lt;p&gt;Another innovation was to adapt conceptors for realtime sequence recognition.  This worked successfully with accelerometer data. The way in which conceptors can be used with boolean logic make them a very powerful tool for pattern classification which we will be exploring more before Marije returns for part 2 of her residency in January.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/chrysalis2.jpg&quot; alt=&quot;Chrsalis&quot; /&gt;
&lt;img src=&quot;/img/chrysalis3.jpg&quot; alt=&quot;Chrsalis&quot; /&gt;
&lt;img src=&quot;/img/chrysalis_shl_lightson.jpg&quot; alt=&quot;Chrsalis&quot; /&gt;
&lt;img src=&quot;/img/chrysalis-diag.jpg&quot; alt=&quot;Chrsalis&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 14 Sep 2017 00:00:00 +0100</pubDate>
        <link>http://www.emutelab.org/blog/chrysalis-report</link>
        <guid isPermaLink="true">http://www.emutelab.org/blog/chrysalis-report</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>machine learning</category>
        
        <category>live coding</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Chrysalis in the SHL</title>
        <description>&lt;p&gt;&lt;b&gt;
Chrysalis&lt;br /&gt;
When: 13 Sept 2017 - 16:00&lt;br /&gt;
Location: &lt;a href=&quot;http://www.sussex.ac.uk/shl/&quot;&gt;Sussex Humanities Lab&lt;/a&gt;&lt;br /&gt;
&lt;br /&gt;
&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.marijebaalman.eu&quot;&gt;Marije Baalman&lt;/a&gt; is an artist and researcher/developer working in the field of interactive sound art. She is currently visiting Sussex, working with Chris Kiefer on serendipity in interactive machine learning algorithms. They will show the results of their work in a performance with Marije’s latest piece Chrysalis, and discuss the work afterwards in a Q&amp;amp;A session.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/chrysalis.jpg&quot; alt=&quot;Algorave&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 13 Sep 2017 00:00:00 +0100</pubDate>
        <link>http://www.emutelab.org/blog/chrysalis</link>
        <guid isPermaLink="true">http://www.emutelab.org/blog/chrysalis</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>machine learning</category>
        
        <category>live coding</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Algorave Brighton 2017</title>
        <description>&lt;p&gt;&lt;b&gt;
Algorave Brighton&lt;br /&gt;
When: 7 Sept 2017 - 19:00–22:30&lt;br /&gt;
Location: &lt;a href=&quot;http://patternsbrighton.com&quot;&gt;Patterns&lt;/a&gt;&lt;br /&gt;
Door tax: FREE&lt;br /&gt;
Facebook event: &lt;a href=&quot;https://www.facebook.com/events/1887328384865474/&quot;&gt;https://www.facebook.com/events/1887328384865474/&lt;/a&gt;&lt;br /&gt;
&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;We are organising an Algorave in Brighton as part of the &lt;a href=&quot;https://www.britishsciencefestival.org&quot;&gt;British Science Festival&lt;/a&gt; programme.&lt;/p&gt;

&lt;p&gt;Algorave is a combination of “algorithms” and “rave”, the opportunity to dance to alien rhythms and freaky visuals, all created from code before your eyes. The Algorave scene is fast-growing around the world, reaching over 50 cities.&lt;/p&gt;

&lt;p&gt;“The scene at an algorave is often what you’d expect from any good techno night - a dark room, engaging visuals. a decent, bass-heavy speaker set-up, and lots of people ready to dance. .. performers at algoraves respond to each other and the audience in real time, often projecting the lines of code onto the walls as they type. lt’s coding as improvisation and experiment..” - The Wire magazine&lt;/p&gt;

&lt;p&gt;“Live coders write computer programs live, while the programs generate their music, but the focus is on people dancing and seriously enjoying themselves” - Dazed and Confused&lt;/p&gt;

&lt;p&gt;”.. not so much a revolution as a de-volution, a rolling back to the backend of music production, where the possibilities of the encoded information inside computer software is open and endless” - Mixmag&lt;/p&gt;

&lt;p&gt;Read a mixmag feature here: &lt;a href=&quot;http://mixmag.net/feature/algorave&quot;&gt;http://mixmag.net/feature/algorave&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Featuring an international lineup of top live coders:
- Renick Bell (Tokyo/UIQ+Halcyon Veil)
- ALGOBABEZ (Leeds+Melbourne/Fractal Meat)
- Alexandra Cärdenas (Berlin) x Slub (Penryn+Sheffield/Chordpunch)
+ Brighton residents Luuma + Thor Magnusson&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/algorave.jpg&quot; alt=&quot;Algorave&quot; /&gt;
&lt;img src=&quot;/img/bluedot.jpg&quot; alt=&quot;Algorave&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 01 Sep 2017 00:00:00 +0100</pubDate>
        <link>http://www.emutelab.org/blog/algorave</link>
        <guid isPermaLink="true">http://www.emutelab.org/blog/algorave</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>algorave</category>
        
        <category>live coding</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Organology Conference Porto</title>
        <description>&lt;p&gt;Emute Lab members Thanos Polymeneas-Liontiris and Thor Magnusson presented work at the &lt;a href=&quot;https://congressorganimusic.wixsite.com/porto2017&quot;&gt;Organology Conference&lt;/a&gt; in Porto, Portugal. The conference consisted of a wide range of instrumental studies, from African and South-American instruments, Baroque flutes and organs, to the volume button in Onde Martenot or Spatial Immersive Instruments.&lt;/p&gt;

&lt;p&gt;We took the opportunity to explore the city, as the biennial &lt;a href=&quot;http://www.liveinterfaces.org&quot;&gt;Live Interfaces Conference&lt;/a&gt; we ran at Sussex last summer will take place in Porto next summer. It promises to be an amazing event, involving &lt;a href=&quot;http://www.casadamusica.com/en/&quot;&gt;Casa De Musica&lt;/a&gt; and many other interesting places in this beautiful city.&lt;/p&gt;

&lt;p&gt;The abstracts from Thanos and Thor follw below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/porto.jpg&quot; alt=&quot;Porto&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Musical Organics: A Heterarchical Approach to Digital Organology&lt;br /&gt;&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;by: Thor Magnusson &lt;b&gt;&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;An important pursuit of organology is the classification of musical instruments. The tree-metaphor has traditionally been the key organisational principle, most prominently applied by Hornbostel and Sachs in their classification from 1914. As Nietzsche, Foucault, and Eco demonstrated, the classification of a domain is an epistemic act; indeed, we find epistemic time periods, where cultures throw different “conceptual nets” over the “rabble of reality” (as Nietzsche put it).
Hornbostel and Sachs acknowledged the problems of division in their classification, stating that instruments are alive and dynamic, whereas systems are static and delineating. This is even more true with new digital instruments, as their complex nature renders them hard to place into classificatory categories. A new analytical approach is required that engages with the repository of digital instruments from a multiplicity of perspectives: materials (e.g., plastic, metal, glass, fibre, cloth); sensors (e.g., ultrasound, bend, potentiometers); sound (e.g., physical models, subtractive, granular, sampling); mapping (e.g., one-to-one, one- to-many, many-to-one, convergent, learned, evolutionary); gestures (e.g., hit, stroke, pluck, shake, bow, blow); reuse of proprioceptive skills (such as the trained playing of keyboard, strings, wind, and percussion); manufacturer (e.g., of sensors, chips, motors), and many more, including cultural context, musical style, and other areas that have been, or indeed will be, called for as extensions to existing organological classifications.&lt;/p&gt;

&lt;p&gt;This presentation will discuss the necessity of shifting our classificatory metaphors from the tree to the rhizome, from hierarchy to heterarchy, pointing to the digital as something that is essentially hard to define due to the lack of tradition, legacy, and institutional framework. The paper discusses the problems of classification of digital instruments and introduce some of the organological work done in the field, leading up to the author’s proposal of Musical Organics. As a theoretical method that applies modern search, machine information retrieval, and representation technologies, musical organics enable researchers to create ad-hoc classifications of instrumental spaces as a collaborative organological research.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;b&gt;Instrumented spaces: two immersive music theatre performances&lt;br /&gt;&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;by: Thanos Polymeneas-Liontiris&lt;b&gt;&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;This presentation revolves around two performances / experiments presented as part of  my research on instrumented/audience reactive sound spaces: Im•medea and the landscape may be a dead star. The works drew inspiration from processes and techniques used in interactive art installations, with the aim of designing and delivering generative Music Theatre.&lt;/p&gt;

&lt;p&gt;Both performances were using the space as an instrument: a series of Infrared (IR) sensors (placed on the walls and ceilings of the spaces) were tracking the movement, position and density of the audience in the rooms. The digital information of these sensors was then analysed and processed by a custom- made algorithm, contributing to the performance in different ways. While in Im•medea it generated the electronic soundscape for the performance, in the landscape may be a dead star it produced the musical score that the performers had to interpret. The result in both cases was an ever-changing music theatre performance, which was evolving by handling the space as an invisible instrument that was played by the movement, position and amount of audience/bodies in space.&lt;/p&gt;

&lt;p&gt;The processes in both performances can be observed as methods for scoring, composing, as well as instruments or performance ecosystems, cybernetic, trans-individual network systems linking audience, performers and technology with a transparent web. These two experiments were the first of a series of experiments of an on-going research on post-digital processes and notions of Posthumanism in Music Theatre.&lt;/p&gt;

</description>
        <pubDate>Wed, 30 Aug 2017 00:00:00 +0100</pubDate>
        <link>http://www.emutelab.org/blog/organology</link>
        <guid isPermaLink="true">http://www.emutelab.org/blog/organology</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>organology</category>
        
        <category>NIME</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Event Report: The Forum for Immersive Augmented Reality Instruments</title>
        <description>&lt;p&gt;The &lt;a href=&quot;https://forumarimi.wixsite.com/arimi&quot;&gt;Forum for Immersive Augmented Reality Instruments&lt;/a&gt;, a two-day networking event, took place on June 19-20th. It brought together diverse participants across University of Sussex schools, research centres and labs, together with representatives from local art organisations and creative industries, with a view to understanding cultural transformations from Augmented Reality (AR), and to build new interdisciplinary research partnerships.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/arimiheader.png&quot; alt=&quot;ARImI Header&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The network event was designed to explore new forms of creation, experience and digital culture through tool and instrument-making, whilst achieving independence from existing distribution structures, and bringing together transdisciplinary discussions on condition of ‘seeing’ (Paul &amp;amp; Toolin 2014, p53) as sensing.&lt;/p&gt;

&lt;p&gt;Day one saw presentations from participants under the themes of culture, sensing, instruments and arts.  On day two, participants explored AR practically through two workshops; an ‘unplugged’ workshop where groups built and discussed hypothetical AR technologies, and a ‘plugged’ workshop where groups experimented with off-the-shelf AR technologies, using visual, audio and haptics materials.&lt;/p&gt;

&lt;p&gt;The Forum for ARImI was led by Cécile Chevalier &amp;amp; Chris Kiefer in partnership with Kirk Woolford, University of Surrey. It was supported by the Doctoral School’s Researcher-Led Initiative (RLI) Fund,  the School of Media, Film, and Music, Sussex Humanities Lab &amp;amp; EMuTe Lab.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/arimi1.JPG&quot; alt=&quot;ARImI Unplugged&quot; /&gt;
&lt;img src=&quot;/img/arimi2.JPG&quot; alt=&quot;ARImI Plugged&quot; /&gt;
&lt;img src=&quot;/img/arimi3.JPG&quot; alt=&quot;ARImI Plugged&quot; /&gt;
&lt;img src=&quot;/img/arimi4.JPG&quot; alt=&quot;ARImI Unplugged&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 28 Jun 2017 00:00:00 +0100</pubDate>
        <link>http://www.emutelab.org/blog/arimi</link>
        <guid isPermaLink="true">http://www.emutelab.org/blog/arimi</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>augmented reality</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Emute Lab @ NIME</title>
        <description>&lt;p&gt;The Experimental Music Technologies Lab at Sussex will have a strong presence at this year’s &lt;a href=&quot;http://www.nime2017.org&quot;&gt;NIME&lt;/a&gt; (New Interfaces for Musical Expression Conference) which is held by Aalborg University in Copenhagen, Denmark. Cecile Chevalier and Andrew Duff present a sound installation, Alice Eldridge and Chris Kiefer will present a paper on their Feedback Cello project, Thor Magnusson will present his paper on Musical Organics, and Alice, Chris and Thor will perform using the Threnoscope and feedback cellos.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;See project descriptions below:&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Alice Eldridge&lt;/b&gt; and &lt;b&gt;Chris Kiefer&lt;/b&gt; present a paper introducing their &lt;b&gt; feedback cello&lt;/b&gt; project, which is a new electroacoustic actuated instrument in which feedback can be induced independently on each string. Built from retro-fitted acoustic cellos, the signals from electromagnetic pickups sitting under each string are passed to a speaker built into the back of the instrument and a transducer on the front of the instrument. Placement of acoustic and mechanical actuators on the resonant body of the cello, mean that this simple analogue feedback system is capable of a wide range of complex self-resonating behaviours. Their paper describes the motivations for building these instruments as both a physical extension to live computer music practice and an electroacoustic augmentation of cello. The design and physical construction is outlined, and modes of performance described with reference to the first six months of performances and installations. Future developments and planned investigations are described.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.emutelab.org/img/feedback_cellos.jpg&quot; alt=&quot;Feedback cellos&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Cecile Chevalier&lt;/b&gt; and &lt;b&gt;Andrew Duff’s&lt;/b&gt; &lt;b&gt;200.104.200.2*&lt;/b&gt; is a sound installation, created as a displaced reenactment of both contemporary digital social practice and the Internet as a memory palace, in which sonifications of memory traces can be performed, stored and replayed as digital data. The work is situated in relation to the art of memory as a form of memory spatialisation, and in relation to post-digital aesthetics, ultimately forming a potential immersive instrument for collective performances. In its conceptual design and instrument-making, 200.104.200.2 is a stainless steel structure 2.5 meters high, 2 meters long and 2 meters wide, from which over 3000 copper wires hang. The structure itself can be entered by participants or performers, as it tracks, connects and extends each of their movements through fine colliding wires that occur within the piece.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.emutelab.org/img/cecileinst.jpg&quot; alt=&quot;Feedback cellos&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Thor Magnusson’s&lt;/b&gt; Threnoscope and the Feedback Cello project of &lt;b&gt;Chris Kiefer&lt;/b&gt; and &lt;b&gt;Alice Eldridge&lt;/b&gt; meet for the first time in a performance at NIME. The feedback cellos are built from acoustic instruments that are modified with electromagnetic pick ups, speakers and transducers, to create a self-resonating drone instrument which can be played either within the extended string tradition or live coded. The threnoscope is a software instrument designed for spatialised, microtonal drone music. In this performance, six channel outputs of the Threnoscope are diffused through a quadrophonic system and also sent to the speakers in the two cellos, affecting the resonant landscapes of the instruments which are simultaneously played by Alice and Chris. Acoustic signals from the cellos are also channeled back to the Threnoscope, creating a multi-instrument, multichannel feedback system. Sonic processes which are physically or digitally initiated by the players on discrete instruments influence each other to form a single dynamical drone system; the liveliness of the ensemble-system as a whole outperforms any one of the players.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.emutelab.org/img/osc.jpg&quot; alt=&quot;Feedback cellos&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Thor Magnusson&lt;/b&gt; presents a paper entitled &lt;b&gt;Contextualising Musical Organics: Ad-hoc Organological Classification Approach&lt;/b&gt;. Here is the abstract:&lt;/p&gt;

&lt;p&gt;New digital musical instruments are difficult for organologists to deal with due to their heterogeneous origins, cross-disciplinary science, and fluid, open-ended nature. NIMEs are studied from a range of disciplines, such as musicology, engineering, human-computer interaction, psychology, design, and performance studies. Attempts to continue traditional organology classifications for electronic and digital instruments have been made, but with adverse results. This paper discusses the problem of the tree-like classifications of digital instruments, proposing an alternative approach: musical organics. Musical organics is a philosophical approach to the problems inherent in organological classification of digital instruments. Shifting the emphasis from hand-coded classification to information retrieval supported search and clustering, we propose an open and distributed system that anyone can contribute to. In order to show how such a system could incorporate a third-party addition, the paper also presents an organological ontogenesis of three new musical instruments: the saxophone, the Minimoog, and the Reactable. This micro-analysis of innovation in the field of musical instruments can help forming a framework for the study of how instruments are adopted in musical culture.&lt;/p&gt;

&lt;p&gt;Thanks to the School of Media, Film and Music and the Sussex Humanities Lab for the support.&lt;/p&gt;

</description>
        <pubDate>Wed, 05 Apr 2017 00:00:00 +0100</pubDate>
        <link>http://www.emutelab.org/blog/NIME2017</link>
        <guid isPermaLink="true">http://www.emutelab.org/blog/NIME2017</guid>
        
        <category>emutelab</category>
        
        <category>NIME</category>
        
        
        <category>blog</category>
        
      </item>
    
  </channel>
</rss>
