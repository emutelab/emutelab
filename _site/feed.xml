<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Emute Lab</title>
    <description>A Music Informatics and Performance Technologies Lab based in the School of Media, Film and Music at the University of Sussex</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Mon, 23 Apr 2018 16:27:48 +0100</pubDate>
    <lastBuildDate>Mon, 23 Apr 2018 16:27:48 +0100</lastBuildDate>
    <generator>Jekyll v3.7.3</generator>
    
      <item>
        <title>Newhaven Soundcamp</title>
        <description>&lt;h3 id=&quot;--may-5th---may-6th-newhaven-community-garden-&quot;&gt;:::::  May 5th - May 6th. Newhaven Community Garden :::::&lt;/h3&gt;

&lt;h3 id=&quot;event-newhaven-soundcamp&quot;&gt;&lt;b&gt;Event: Newhaven Soundcamp&lt;/b&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/img/westbeach.jpg&quot; alt=&quot;soundcamp&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Join us for newhaven soundcamp over the International Dawn Chorus weekend of 5th to 6th May 2018, when small groups of people around the world will sleep outside and listen.&lt;/p&gt;

&lt;p&gt;International Dawn Chorus Day is a world wide celebration of the dawn chorus initiated by the Wildlife Trusts to raise awareness of the deep importance of nature conservation and close relationship between human wellbeing and that of all other living species.&lt;/p&gt;

&lt;p&gt;Newhaven Soundcamp is part of &lt;a href=&quot;http://soundtent.org/soundcamp_reveil.html&quot;&gt;REVEIL&lt;/a&gt;, an international network of listening points. Instigated by arts collective &lt;a href=&quot;http://soundtent.org/soundcamp_about.html&quot;&gt;soundcamp&lt;/a&gt;, REVEIL curates a live radio broadcast from these open microphones as the sun rises around the globe on the International Dawn Chorus weekend.&lt;/p&gt;

&lt;p&gt;Newhaven Soundcamp is a small scale event for local residents to act as a simple, potent point for ecological, social, intellectual, aesthetic and spiritual engagement with Newhaven’s acoustic environments - and linking this spot of Sussex Downs Biosphere (The Living Coast)  to an international network of site of ecological and sonic interest.&lt;/p&gt;

&lt;p&gt;The broadcast will be made using a DIY radio transmitter constructed from a raspberry Pi.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.eventbrite.co.uk/e/soundcamp-newhaven-tickets-45174650596&quot;&gt;Further information and free tickets&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Listen in to the stream of International Dawn Chorus Weekend &lt;a href=&quot;http://streams.soundtent.org/2018/streams&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;Presented in association with &lt;a href=&quot;https://www.thelivingcoast.org.uk/&quot;&gt;The Living Coast&lt;/a&gt;, kindly hosted by &lt;a href=&quot;http://growingtogethernewhaven.org/&quot;&gt;Growing Together Newhaven&lt;/a&gt; and supported by &lt;a href=&quot;http://www.sussex.ac.uk/shl/&quot;&gt;Sussex Humanities Lab&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Mon, 23 Apr 2018 00:00:00 +0100</pubDate>
        <link>http://localhost:4000/blog/soundcamp</link>
        <guid isPermaLink="true">http://localhost:4000/blog/soundcamp</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>ecoacoustics</category>
        
        <category>DIY tech</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Seminar: Gianluca Memoli and Spyros Polychronopoulos (Interact Lab, Informatics)</title>
        <description>&lt;p&gt;&lt;b&gt;::::: Thursday, April 26th, 2018. 2-4pm - Recital Room (Falmer House 120) :::::&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;We have two talks from members of the Interact Lab at Sussex, who are both researchers in Acoustic Levitation and Human Computer Interaction.&lt;/p&gt;

&lt;h2 id=&quot;spyros-polychronopoulos-new-ways-to-create-and-deliver-music&quot;&gt;Spyros Polychronopoulos: New ways to create and deliver music&lt;/h2&gt;

&lt;p&gt;The aesthetics of dead (as pre-recorded) and live (as endless unique reproduced) music. Challenging the “here and now” of the work of art with programmable performers.&lt;/p&gt;

&lt;p&gt;References&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.marxists.org/reference/subject/philosophy/works/ge/benjamin.htmhttps://www.marxists.org/reference/subject/philosophy/works/ge/benjamin.htm&quot;&gt;Walter Benjamin (1936)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://emporium.room40.org/products/583176-spyros-polychronopoulos-live-electronic-music-sound-object&quot;&gt;Live Electronic Music Sound Object (2016)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/docs/Music perception and the fluctuation of utopia.pdf&quot;&gt;Music perception and the fluctuation of utopia&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;bio&quot;&gt;Bio&lt;/h3&gt;

&lt;p&gt;Spyros Polychronopoulos was born in Athens, Greece in 1980. His interest in sound, both as a physical phenomenon as well as a form of art, began at an early age. He holds a degree in Physics and a PhD in Electrical Engineering from University of Patras, Greece. His thesis focused on tuning the acoustics of closed spaces and he has published a number of papers in this field. After relocating to London in 2014, he gained three years of practical experience working as an acoustic consultant. Further to his research in sound, he has developed unique sound objects, released 15 albums and performed a number of concerts around the world. Spyros regularly leads workshops and lectures discussing the new technologies in composition and aesthetics of sound. He currently works as a Research Fellow in the Informatics Department at the University of Sussex, UK, researching ‘Human-computer Interaction for Acoustic Levitation’.&lt;/p&gt;

&lt;h2 id=&quot;gianluca-memoli-spatial-sound-using-meta-materials&quot;&gt;Gianluca Memoli: Spatial Sound using Meta-materials&lt;/h2&gt;

&lt;p&gt;When an architect, a sound engineer or a theatre director designs the acoustics of a space, the presence of sound is binary: it is either there for everyone or not. We manage light differently, though: well-established technologies allows us to exploit light and shadows, beams that follow characters, diffused or focused spotlights. The technology for achieving similar results with sound is simply not there: since directional speakers still don’t maintain their promises in terms of performance, large arrays of speakers are still used for beam-forming, either software controlled or spatially arranged. In this talk, I will discuss the opportunities offered by acoustic meta-materials to achieve spatial control on sound in static applications. These can be placed in front of loudspeakers just like lenses or filters would be positioned in front of a light source, for achieving diffraction-limited effects. I will also discuss where, in my opinion, these new tools may lead us in the short and medium term and whether they will eventually give us the same control on sound that we have on light, across all the frequency range.&lt;/p&gt;

&lt;h3 id=&quot;bio-1&quot;&gt;Bio&lt;/h3&gt;

&lt;p&gt;Gianluca has worked in acoustics for 14 years, after his PhD. His acoustic research (soundscapes, industrial and medical ultrasound) has taken him to influence EU legislation and ISO standards, to work with local authorities and hospitals, to measure the largest bubble in the word and to find new ways to prolong shelf life of honey using ultrasound. He is a passionate science communicator and has worked with creatives of all sorts, from garden designers to choreographers.  As a newly appointed lecturer in Informatics at Sussex, he is currently looking at ways to give creatives the same control on sound that they have on light using specially engineered, 3D-printed, passive materials.&lt;/p&gt;
</description>
        <pubDate>Mon, 23 Apr 2018 00:00:00 +0100</pubDate>
        <link>http://localhost:4000/blog/interactLabSeminar</link>
        <guid isPermaLink="true">http://localhost:4000/blog/interactLabSeminar</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>talk</category>
        
        <category>acoustics</category>
        
        <category>3D printing</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Perspectives in Ecoacoustics</title>
        <description>&lt;p&gt;&lt;b&gt;::::: Thursday, May 3rd, 2018. 4pm - Sussex Humanities Lab :::::&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Talk: Perspectives in Ecoacoustics – Prof Almo Farina, University of Urbino, Italy&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;We are delighted to welcome Prof Almo Farina, a naturalist and landscape ecologist and one of the pioneers of Ecoacoustics - the investigation of the ecological role of sounds.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.sussex.ac.uk/shl/&quot;&gt;Sussex Humanities Lab&lt;/a&gt; (Silverstone Building, SB211) - All welcome!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/farina_ALMO_FARINA.jpg&quot; alt=&quot;Farina&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;When you are happy, your voice is more fresh. When you are tired or annoyed, it changes. The same applies to the environment.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;perspectives-in-ecoacoustics-a-contribution-to-defining-a-discipline&quot;&gt;Perspectives in Ecoacoustics: A contribution to defining a discipline&lt;/h3&gt;

&lt;p&gt;Ecoacoustics is a recently established discipline that investigates the ecological role of sounds. A set of processes in four [&lt;em&gt;adaptive, behavioural, geographical, ecosemiotic&lt;/em&gt;] domains supports and guides the development of ecoacoustics.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;em&gt;adaptive&lt;/em&gt;  domain includes evolutionary mechanisms that join sound typology with the physical and biological characteristics of the environment and create frequency partitioning among species to reduce competition.&lt;/li&gt;
  &lt;li&gt;The behavioural  domain addresses interspecific signals associated with geophysical and anthropogenic sounds that operate to shape temporary acoustic communities and orient species to select suitable acoustic habitats.&lt;/li&gt;
  &lt;li&gt;The geographic  domain pertains to the geography of sound, an entity composed of three subordinate acoustic objects: sonotopes, soundtopes, and sonotones, which are operationally delimited in a geographical and temporal space by the distribution of the ecoacoustic events. The ecoacoustic events allow the classification of complex configurations/patterns of acoustic signals and represent the grain of a soundscape mosaic.&lt;/li&gt;
  &lt;li&gt;The ecosemiotic  domain operates by  communication mechanisms within the species level according to a function-specific perception of the acoustic information facilitated by encoding/decoding processes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Long-term monitoring, habitat health, biodiversity assessment, soundscape conservation and ecosystem management makes ecoacoustics relevant in several fields where human intrusion in ecosystems is growing at an unprecedented rate.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/farina_SET.jpg&quot; alt=&quot;recorder&quot; /&gt;
&lt;em&gt;SET – Soundscape Explorer [Terrestrial]) digital recorder. Photo: Almo Farina&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;biography&quot;&gt;Biography&lt;/h3&gt;
&lt;p&gt;Almo Farina is an Italian naturalist and Professor of Ecology in the Department of Pure and Applied Sciences, Urbino University, Italy. He has dedicated the last ten years to elaborate new theories in landscape ecology, soundscape ecology and ecoacoustics. He considers the protection of the biological diversity integrated with the human cultural heritage and well-being, a priority of its scientific and human mission. In 2014 Almo was elected the first President of the &lt;a href=&quot;https://sites.google.com/site/ecoacousticssociety/&quot;&gt;International Society of Ecoacoustics&lt;/a&gt;, and in 2015 he founded the &lt;a href=&quot;http://www.iinsteco.org/&quot;&gt;International Institute of Ecoacoustics&lt;/a&gt; .&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Author of &lt;a href=&quot;https://www.wiley.com/en-gb/Ecoacoustics:+The+Ecological+Role+of+Sounds-p-9781119230694&quot;&gt;Ecoacoustics: The Ecological Role of Sounds&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Editor-in-Chief of the &lt;a href=&quot;https://www.veruscript.com/journals/journal-of-ecoacoustics/&quot;&gt;Journal of Ecoacoustics&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.jmecology.com/&quot;&gt;Journal of Mediterranean Ecology&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.codebiology.org/&quot;&gt;Code Biology&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;p&gt;Presented in association with &lt;a href=&quot;http://www.sussex.ac.uk/shl/&quot;&gt;Sussex Humanities Lab&lt;/a&gt; and &lt;a href=&quot;http://www.sussex.ac.uk/ssrp/&quot;&gt;Sussex Sustainability Research Programme&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 08 Mar 2018 00:00:00 +0000</pubDate>
        <link>http://localhost:4000/blog/almoFarina</link>
        <guid isPermaLink="true">http://localhost:4000/blog/almoFarina</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>talk</category>
        
        <category>ecoacoustics</category>
        
        <category>acoustic ecology</category>
        
        <category>soundscape</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>One Thousand Mindreaders</title>
        <description>&lt;p&gt;&lt;b&gt;::::: Thursday, March 15th, 2018 @ Caxton Arms, 6:30 pm :::::&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Where: &lt;a href=&quot;https://www.caxtonarms.co.uk&quot;&gt;Caxton Arms&lt;/a&gt;&lt;/b&gt;&lt;br /&gt;
36 North Gardens &lt;br /&gt;
Brighton.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;NOTE: This event was supposed to be in the SHL, but due to the USS STRIKE it is now running it as part of the exiting &lt;a href=&quot;https://docs.google.com/document/d/1ywtMO06wlxqRXftEGwpUUZQhtXwCyS_i6qWLMW43_eA/edit&quot;&gt;SussexforUSS&lt;/a&gt; events&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt; ALL WELCOME !&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Magician and Human-Machine Interactor &lt;a href=&quot;http://stuartnolan.com&quot;&gt;Stuart Nolan&lt;/a&gt; will be giving a workshop in mindreading, followed by talk on his practice as a magician. Stuart has a track record in training mindreading skills in an hour, so it is certainly worth coming to this session to learn this important art. Join us at the &lt;a href=&quot;https://www.caxtonarms.co.uk&quot;&gt;Caxton Arms&lt;/a&gt; Pub - All welcome!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/mindreaders.jpg&quot; alt=&quot;MindReaders&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Workshop: One Thousand Mindreaders (6:30-7:30 pm)&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;One Thousand Mindreaders is a year-long collaborative artwork during which the artist Stuart Nolan will train one thousand new mindreaders.&lt;/p&gt;

&lt;p&gt;Participants will learn the skill of muscle reading, sensing the small subconscious movements of another person’s hands. This will enable them to recreate drawings that another person is merely thinking of.
They will also learn how to find objects that another person has hidden in a room or building.&lt;/p&gt;

&lt;p&gt;Both the drawings and the found objects will be exhibited in 2019 and trainee mindreaders will be offered the opportunity to demonstrate their new skills for a public audience at a series of performances throughout 2018 and 2019.&lt;/p&gt;

&lt;p&gt;In this interactive session, we will also explore the role of touch in interaction, learning to read each other’s minds using techniques based on Victorian mindreading tricks, games, and experiments, and improved with current research into the neuroscience of touch.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Talk: Beyond The Feelies (8 pm)&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;‘Of all our senses, touch is the one considered least deceptive and the most secure.’ - René Descartes&lt;/p&gt;

&lt;p&gt;Touch is the most intimate and emotional of the senses. It is no accident that when we speak of affecting someone emotionally we say we have touched them. We feel emotions and we feel each other’s joy and pain. Touch is central when negotiating issues of trust, veracity, falsehood, agency, difference, and connection.&lt;/p&gt;

&lt;p&gt;In the essay Silence is Golden, Aldous Huxley wrote of his disgust with the coming of sound to film. He parodied the “talkies” in Brave New World by imagining a future where film would include a sense of touch, “Going to the Feelies this evening, Henry?… There’s a love scene on a bearskin rug; they say it’s marvelous. Every hair of the bear reproduced. The most amazing tactual effects…” This crude idea of touch as something that is separate to film distracts us from the fact that cinema has always been a bodily, visceral experience. This is true of all media but becomes more visible with interaction, VR, haptics, and immersion.&lt;/p&gt;

&lt;p&gt;In this interactive session, we will explore the role of touch in interaction, learning to read each other’s minds using techniques based on Victorian mindreading tricks, games, and experiments, and improved with current research into the neuroscience of touch. Stuart will give a brief insight into his recent work on touch in healthcare, theatre, dance, sport, robotics, and 5G and we will explore the potential of technology to capture, measure, and transmit touch data in mediated communication, interaction, art, and storytelling.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stuart.jpg&quot; alt=&quot;MindReaders&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Further Info:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;www.stuartnolan.com&quot;&gt;www.stuartnolan.com&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;www.1000mindreaders.com&quot;&gt;www.1000mindreaders.com&lt;/a&gt;&lt;br /&gt;
Twitter: &lt;a href=&quot;https://twitter.com/1000mindreaders&quot;&gt;@1000Mindreaders&lt;/a&gt;&lt;br /&gt;
Instagram: onethousandmindreaders&lt;br /&gt;
Facebook: @OneThousandMindreaders&lt;br /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 06 Feb 2018 00:00:00 +0000</pubDate>
        <link>http://localhost:4000/blog/mindreaders</link>
        <guid isPermaLink="true">http://localhost:4000/blog/mindreaders</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>performances</category>
        
        <category>mind reading</category>
        
        <category>HCI</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>BEER: Dark Matter at ACCA</title>
        <description>&lt;p&gt;&lt;b&gt;::::: Wednesday, February 21st, 2018 @ ACCA, 8pm :::::&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;In collaboration with the Attenborough Centre for the Creative Arts, we are organising an eventful day with the &lt;a href=&quot;http://www.beast.bham.ac.uk/offspring/beer/&quot;&gt;Birmingham Ensemble for Electroacoustic Research&lt;/a&gt; (BEER).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/BEER.png&quot; alt=&quot;BEER&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Performance&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;This performance by the Birmingham Ensemble for Electroacoustic Research, created in collaboration with the &lt;a href=&quot;http://artcms.web.cern.ch/artcms/&quot;&gt;art@CMS&lt;/a&gt; project at CERN in Switzerland, involves the real-time sonification of data streams from the Large Hadron Collider, the world’s largest and most complex particle accelerator. Experimental data containing clues towards possible ‘new physics’ becomes the raw material for improvised music and visualisations programmed by the ensemble with an aim to creating a result that while beautiful, is also both musically and scientifically meaningful.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Workshop&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;::::: @ ACCA, 3-5pm :::::&lt;/p&gt;

&lt;p&gt;This workshop for composers and artists explores the possibilities of using scientific data as a resource for music and sonic art, with particular focus on sonifying data from the Large Hadron Collider at CERN, the world’s largest particle accelerator. An introduction to the physics involved will be followed by an exploration of strategies for converting the data into sound. Previous experience of computer music environments is useful, but not required.&lt;/p&gt;

&lt;p&gt;Places in the workshop are limited. Please sign up &lt;a href=&quot;https://goo.gl/forms/2cTbIecn62yPcwmf1&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/darkmatter.png&quot; alt=&quot;Dark Matter Workshop&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Further information about the event on the &lt;a href=&quot;https://www.attenboroughcentre.com/events/1643/dark-matter?spektrix_bounce=true&quot;&gt;ACCA website&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 09 Jan 2018 00:00:00 +0000</pubDate>
        <link>http://localhost:4000/blog/darkmatter</link>
        <guid isPermaLink="true">http://localhost:4000/blog/darkmatter</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>performances</category>
        
        <category>sonification</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>EMuTeLab 0 @ The Rose Hill, Brighton</title>
        <description>&lt;p&gt;&lt;img src=&quot;/img/emutelab0_webflyer.png&quot; alt=&quot;EMuTeLab0 Gig Flyer&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Emute Lab presents… an evening of exciting experimental music&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Join us at the Rose Hill club to experience some cutting-edge music with new exciting instruments and audiovisual technologies. On the bill are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;JesterN (Laser Drawing / Modular Synth)&lt;/li&gt;
  &lt;li&gt;Marije Baalman (Chrysalis / Installations)&lt;/li&gt;
  &lt;li&gt;Brain Dead Ensemble (Thren0scope / Feedback Cellos / Feedback Double Bass)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;January 12th, 2018. 7pm. at &lt;a href=&quot;http://www.therosehill.co.uk&quot;&gt;The Rose Hill&lt;/a&gt;, Brighton. £5&lt;/p&gt;

&lt;p&gt;&lt;b&gt;JesterN: Laser Drawing&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;JesterN’s Laser Drawing is a synesthetic experience in which you can listen to what you see, and see what you listen to
Using its modular synthesizer, JesterN manipulates electric voltages live, sending them in exactly the same way to the speakers to create sound and to the laser to create its curvy shapes with vivid colors. An artisanal live show in which every beat and every shape is simultaneously improvised on the stage. Being cooked on the spot, music-wise it depends on the space and on the vibe: it can go from drones, to harsh noise, from techno straight beats to IDM syncopations, or something completely diferent …&lt;/p&gt;

&lt;p&gt;Alberto Novello a.k.a. JesterN is a scientist, composer, sound and video artist. In his works, he has assisted Alvin Lucier, Nicholas Collins and Trevor Wishart. His artistic works have been presented in international festivals such as Amsterdam Dance Event, Venice Biennale, Impuls Tanz Vienna, Seoul International Music Festival, Emu Fest Roma, Monaco Electroacoustique, New York Computer Music Festival, Rewire Festival and conferences such as NIME, ICMC, ISMIR, ICMPC, ICA, ICCE and ESSEM and institutes for contemporary music research such as CCMAS in Mexico, GRM in France, Logos Foundation in Belgium, STEIM Amsterdam, IEM Graz, OMI New York, the Royal Conservatory of Den Haag, Conservatory of Padua.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.jestern.com/&quot;&gt;http://www.jestern.com/&lt;/a&gt;&lt;/p&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/235351838&quot; width=&quot;640&quot; height=&quot;360&quot; frameborder=&quot;0&quot; webkitallowfullscreen=&quot;&quot; mozallowfullscreen=&quot;&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;a href=&quot;https://vimeo.com/235351838&quot;&gt;JesterN Laser Drawing @AESON Festival 2017&lt;/a&gt; from &lt;a href=&quot;https://vimeo.com/jestern&quot;&gt;jestern&lt;/a&gt; on &lt;a href=&quot;https://vimeo.com&quot;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;b&gt;Marije Baalman&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;A cocoon lies on stage, barely recognisable in the dim light. Slow tones are sounding in the space. The light seems to change color – the tones are changing slowly in pitch. The cocoon seems to move – the light seems to get brighter and gradually shift color. Suddenly a fast movement – a shrieking sound fills the space – then again everything quiets down – the movement, the sound, the light.&lt;/p&gt;

&lt;p&gt;Chrysalis is a performative environment where the focus is on slow movements – becoming aware of the minimal movements of the body, both conscious and unconscious movements. It is about interaction on a long timescale – involving multiple senses (hearing, sight, haptic).&lt;/p&gt;

&lt;p&gt;Marije Baalman is an artist and researcher/developer working in the field of interactive sound art.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.marijebaalman.eu/&quot;&gt;https://www.marijebaalman.eu/&lt;/a&gt;&lt;/p&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/183344106&quot; width=&quot;640&quot; height=&quot;360&quot; frameborder=&quot;0&quot; webkitallowfullscreen=&quot;&quot; mozallowfullscreen=&quot;&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;a href=&quot;https://vimeo.com/183344106&quot;&gt;Chrysalis - a teaser&lt;/a&gt; from &lt;a href=&quot;https://vimeo.com/user16929243&quot;&gt;Marije Baalman&lt;/a&gt; on &lt;a href=&quot;https://vimeo.com&quot;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;b&gt;Brain Dead Ensemble&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;The Brain Dead Ensemble consists of members of the Emute Lab interested in feedback in acoustic and electronic instruments, and the combination of those. The audiovisual live coding instrument, Threnoscope, will feed sound directly into the acoustic instruments (two cellos and a double bass) via their mechanical actuators.&lt;/p&gt;

&lt;p&gt;Thor Magnusson (Threnoscope, &lt;a href=&quot;http://www.ixi-audio.net/&quot;&gt;http://www.ixi-audio.net/&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Thanos Polymeneas Liontiris (Feedback Bass, &lt;a href=&quot;http://thanospl.net/&quot;&gt;http://thanospl.net/&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Alice Eldridge&lt;/p&gt;

&lt;p&gt;Chris Kiefer&lt;/p&gt;

&lt;p&gt;(Feedback Cell, Feedback Cellos, &lt;a href=&quot;http://feedbackcell.ooo/&quot;&gt;http://feedbackcell.ooo/&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;There is no video of the Brain Dead Ensemble (they have not figured out how to do that), but there are some of the Threnoscope, cello and bass (Thor, Alice and Thanos):&lt;/p&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/179079463&quot; width=&quot;640&quot; height=&quot;360&quot; frameborder=&quot;0&quot; webkitallowfullscreen=&quot;&quot; mozallowfullscreen=&quot;&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;a href=&quot;https://vimeo.com/179079463&quot;&gt;Fermata at OSC in Brighton&lt;/a&gt; from &lt;a href=&quot;https://vimeo.com/thormagnusson&quot;&gt;thormagnusson&lt;/a&gt; on &lt;a href=&quot;https://vimeo.com&quot;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;and two feedback cellos (Alice and Chris):&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/gazcpDOFTz0&quot; frameborder=&quot;0&quot; gesture=&quot;media&quot; allow=&quot;encrypted-media&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

</description>
        <pubDate>Thu, 04 Jan 2018 00:00:00 +0000</pubDate>
        <link>http://localhost:4000/blog/emutelab0</link>
        <guid isPermaLink="true">http://localhost:4000/blog/emutelab0</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>performances</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Emute Lab in 2017</title>
        <description>&lt;p&gt;The Experimental Music Technology Lab has had a busy year in 2017. Some of the key events are listed below:&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Performances&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Algorave Brighton&lt;/b&gt; - September 7th. The Emute Lab co-organised an &lt;a href=&quot;https://algorave.com&quot;&gt;Algorave&lt;/a&gt; hosted by the British Science Festival. Performances with Algobabes, Slub, Renick Bell, Chris Kiefer and Thor Magnusson. See information &lt;a href=&quot;https://www.britishsciencefestival.org/event/algorave/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Luuma @ London Algorave&lt;/b&gt;&lt;br /&gt;
Chris Kiefer performing at the &lt;a href=&quot;https://algorave.com/london/&quot;&gt;London Algorave&lt;/a&gt; in June.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Syncphonia ‘Orchestra Hero’ event at the British Science Festival&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Thor Magnusson at Borealis&lt;/b&gt; &lt;br /&gt;
Threnoscope + Voluspa at the &lt;a href=&quot;http://www.borealisfestival.no/2017/threnoscope-thor-magnusson-2/&quot;&gt;Borealis Festival&lt;/a&gt; in Bergen, March.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Chevalier &amp;amp; Duff, 200.104.200.2,&lt;/b&gt; @ NIME 2017&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Feedback Cello Performances&lt;/b&gt; &lt;br /&gt;
At Bournemouth, Loop Berlin, HAL@SARC, NIME, Spirit of Gravity, Mengi, Algomech, DesInC&lt;br /&gt; see &lt;a href=&quot;http://feedbackcell.ooo/live/&quot;&gt;http://feedbackcell.ooo/live/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;O, One a 5 minute opera for two Nao Robots and cello&lt;/b&gt; &lt;br /&gt;
Words and music by Evelyn Ficarra, premiered at the Robot Opera Mini-Symposium on 15th June 2017. Performed by two Nao Robots (as themselves); Alice Eldridge (cello); directed /designed by Tim Hopkins; co-devised and programmed by Ron Chrisley. 
&lt;a href=&quot;http://www.sussex.ac.uk/cromt/archive/robotopera&quot;&gt;http://www.sussex.ac.uk/cromt/archive/robotopera&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Ficarra, Evelyn. Ghost Cup - a sound installation.&lt;/b&gt;&lt;br /&gt; 
Columbia University, April 7-8 2017, New York USA
&lt;a href=&quot;http://blogs.cuit.columbia.edu/reembodiedsound/&quot;&gt;http://blogs.cuit.columbia.edu/reembodiedsound/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Ficarra, Evelyn. Scores for objects and electronics with Heather Frasch&lt;/b&gt;&lt;br /&gt; 
Studio 8, 8th May 2017, Berlin.
&lt;a href=&quot;https://www.facebook.com/events/1473355456065457/&quot;&gt;https://www.facebook.com/events/1473355456065457/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Thanos Polymeneas Liontiris, ACCA, 13 February 2017&lt;/b&gt;
A Magnificent Crossbreeding of Protein and Tinplate&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;b&gt;Publications&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Bright, D. (2017) Conjuring the sonic ghosts of industrial and post-industrial spaces, in &lt;a href=&quot;http://www.cambridgescholars.com/the-post-industrial-landscape-as-site-for-creative-practice&quot;&gt;The Post-Industrial Landscape as Site for Creative Practice&lt;/a&gt;, Cambridge Scholars Publishing.&lt;/p&gt;

&lt;p&gt;Eldridge, Alice and Kiefer, Chris (2017) The self-resonating feedback cello: interfacing gestural and generative processes in improvised performance. New Interfaces for Music Expression. Download &lt;a href=&quot;http://homes.create.aau.dk/dano/nime17/papers/0005/paper0005.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Magnusson, Thor (2017) Musical Organics: A Heterarchical Approach to Digital Organology&lt;br /&gt;
in Journal of New Music Research. Download &lt;a href=&quot;http://www.tandfonline.com/doi/full/10.1080/09298215.2017.1353636&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Magnusson, Thor (2017) Contextualizing Musical Organics: An Ad-hoc Organological Classification Approach &lt;br /&gt;
NIME 2017 conference. Download &lt;a href=&quot;http://ixi-audio.net/thor/Magnusson_NIME2017_MusicalOrganics.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Webb, Sharon, Kiefer, Chris, Jackson, Ben, Baker, James and Eldridge, Alice (2017) Mining oral history collections using music information retrieval methods. Music Reference Services Quarterly. Download &lt;a href=&quot;http://www.tandfonline.com/doi/abs/10.1080/10588167.2017.1404307&quot;&gt; here&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;b&gt;Events&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Interdisciplinary perspectives: Machine Listening &amp;amp; Listening Machines&lt;/b&gt;&lt;br /&gt;
April 27-28. Sussex Humanities Lab, University of Sussex, Brighton&lt;br /&gt;
&lt;a href=&quot;http://www.algorithmiclistening.org/workshop1/ &quot;&gt;http://www.algorithmiclistening.org/workshop1/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Understanding Distributed Agency Between Listening Algorithms and Humans&lt;/b&gt;&lt;br /&gt;
May 31-June 1. Sonic Arts Research Centre, Queen’s University Belfast&lt;br /&gt;
&lt;a href=&quot;http://www.algorithmiclistening.org/workshop2/&quot;&gt;http://www.algorithmiclistening.org/workshop2/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Future Implications and Applications of Algorithmic Listening&lt;/b&gt;&lt;br /&gt;
Sept 14-15. University of Sussex, Brighton&lt;br /&gt;
&lt;a href=&quot;http://www.algorithmiclistening.org/workshop3/&quot;&gt;http://www.algorithmiclistening.org/workshop3/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Long table – Humanising Algorithmic Listening in Culture and Conservation&lt;/b&gt;&lt;br /&gt;
Sept 14th 20:00 as part of the 2017 Brighton Digital Festival&lt;br /&gt;
&lt;a href=&quot;http://brightondigitalfestival.co.uk/events/humanising-algorithmic-listening-culture-conservation &quot;&gt;http://brightondigitalfestival.co.uk/events/humanising-algorithmic-listening-culture-conservation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;DIY radio transmission – Pi Streambox Workshop&lt;/b&gt;&lt;br /&gt;
Oct 12th 14:00 and 18:30 as part of the Brighton Digital Festival &lt;br /&gt;
&lt;a href=&quot;http://brightondigitalfestival.co.uk/events/diy-radio-transmission-pi-streambox-workshop&quot;&gt;http://brightondigitalfestival.co.uk/events/diy-radio-transmission-pi-streambox-workshop&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Residency at CNMAT and CMC&lt;/b&gt;&lt;br /&gt;
In May, Thor Magnusson did a residency at CNMAT, Berkeley which included giving a lecture on current research. In June, he visited CMC, Columbia with the same programme. &lt;br /&gt;
Info &lt;a href=&quot;http://cnmat.berkeley.edu/projects/sonic-writing-research&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Marije Baalman residency at Sussex&lt;/b&gt;&lt;br /&gt;
Marije Baalman did a residency at Emute Lab collaborating with Chris Kiefer. This will be continued in January 2018, ending with a gig.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Forum for Augmented Reality Immersive Instruments (ARIMI)&lt;/b&gt;
Cecile Chevalier &amp;amp; Chris Kiefer in partnership with Kirk Woolford, June 19-20, 2017&lt;br /&gt; 
&lt;a href=&quot;http://users.sussex.ac.uk/~ad207/arimi/&quot;&gt;http://users.sussex.ac.uk/~ad207/arimi/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Emute Lab in Reykjavik&lt;/b&gt;&lt;br /&gt;
Alice Eldridge and Chris Kiefer did a residency at the Icelandic Arts Academy, also performing at &lt;a href=&quot;https://mengi.net/events/2017/10/28/feb12th&quot;&gt;Mengi&lt;/a&gt;, in Reykjavik.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Alberto Novello visiting researcher&lt;/b&gt;&lt;br /&gt;
Alberto Novello gave a &lt;a href=&quot;http://www.emutelab.org/blog/novello&quot;&gt;talk, workshop and tutorials&lt;/a&gt;. Talk title: Invisible to visible: bio signals and possible applications in the arts&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;b&gt;Conferences&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Evelyn Ficarra&lt;/b&gt; ‘The Sound Object in Theatrical and Installation Contexts’, Re-embodied Sound Conference, Columbia University, New York 8th April 2017
&lt;a href=&quot;http://blogs.cuit.columbia.edu/reembodiedsound/&quot;&gt;http://blogs.cuit.columbia.edu/reembodiedsound/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Alice Eldridge at a panel @ Loop 2017&lt;/b&gt;
Alice Eldridge on a panel on hybrid instruments at Ableton’s Festival of music, technology and creative practice - Loop, Berlin. &lt;br /&gt;
Alice and Chris Kiefer will also give a performance in the maker space. 
&lt;a href=&quot;https://loop.ableton.com/2017/program/activity/motors-magnets-and-motion-electronic-music-instruments-physical-world/&quot;&gt;Info here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Alice Eldridge and Danny Bright&lt;/b&gt; at Sound &amp;amp; Environment
Alice - Paper &amp;amp; Plenary Panel
Danny - Installation: Thrumming Halls
&lt;a href=&quot;http://www2.hull.ac.uk/fass/drama,-music-and-screen/conferences/sound--environment-2017.aspx&quot;&gt;http://www2.hull.ac.uk/fass/drama,-music-and-screen/conferences/sound–environment-2017.aspx&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Robot Opera Mini Symposium&lt;/b&gt;, organised by Evelyn Ficarra, featuring talks by Chris Kiefer, Ron Chrisley, Thanos Polymeneas-Liontiris, with brief introduction by Evelyn Ficarra ‘Why Robot Opera’. The day examined issues of embodiment, artificial intelligence and vocality through scholarly research and creative practice. 15 June 2017. 
&lt;a href=&quot;http://www.sussex.ac.uk/cromt/archive/robotopera&quot;&gt;http://www.sussex.ac.uk/cromt/archive/robotopera&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanos Polymeneas Liontiris, in The Operatic Symposium, University of Sussex, 19th May 2017, title:
The Operatic Bot&lt;/p&gt;

&lt;p&gt;Thanos Polymeneas Liontiris, in Robot Opera Symposium, University of Sussex, 17th June 2017, title:
Voices Without Bodies: The Operatic Bot in immersive performance&lt;/p&gt;

&lt;p&gt;Thanos Polymeneas Liontiris, in 6th International Scientific Meeting for Sound and Musical Instruments, Porto, August 2017, title:
Instrumented Spaces: Two Immersive Music Theatre Experiences&lt;/p&gt;

&lt;p&gt;Thanos Polymeneas Liontiris, in Annual Conference of Theatre and Performance Research Association (TaPRA), University of Salford, August 2017, title:
Cyber-Divas: Vocaloids as Postdigital Opera Singers&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;b&gt;Software&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Syncphonia - &lt;a href=&quot;http://www.syncphonia.co.uk/&quot;&gt;http://www.syncphonia.co.uk/&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;b&gt;Research grants&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://gtr.rcuk.ac.uk/projects?ref=AH%2FR002657%2F1&quot;&gt;MIMIC&lt;/a&gt; - Thor Magnusson and Chris Kiefer in collaboration with Goldsmiths and Durham University.&lt;/p&gt;

</description>
        <pubDate>Sun, 31 Dec 2017 00:00:00 +0000</pubDate>
        <link>http://localhost:4000/blog/year2017</link>
        <guid isPermaLink="true">http://localhost:4000/blog/year2017</guid>
        
        <category>emutelab</category>
        
        <category>eventa</category>
        
        <category>PhD</category>
        
        <category>NIME</category>
        
        <category>sonificiaton</category>
        
        <category>instruments</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Emute Lab PhD presentations</title>
        <description>&lt;p&gt;&lt;b&gt;:::: Monday, October 30th, 1.00pm @ SHL ::::&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;We have two new PhD researchers starting with us this autumn, Halldór Úlfarsson and Iain Emsley. During this 50 min lunch time talk we will have two 15 minute presenations and then dedicate 20 minutes to discuss these fresh and exciting research projects.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Halldór Úlfarsson&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Title: &lt;b&gt;Infiltrating History&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;What makes a musical instrument real? Is it real when music is being made on it or is it perhaps more real when it gets mentioned in a book or when it is placed in an archive for musical instruments; when it becomes history. I tell the tale of the halldorophone and how it graduated from being a postmodern joke to a musical instrument with something of an established culture of use. I consider if the halldorophone is actually a different object by now (or if the joke has just gotten better).&lt;/p&gt;

&lt;p&gt;Bio: &lt;a href=&quot;http://www.halldorulfarsson.info&quot;&gt;Halldór Úlfarsson&lt;/a&gt; (IS) has been working with musicians on projects involving his electro acoustic string instrument the halldorophone for about a decade. Compositions for the halldorophone have been featured in various genres of music in a variety of contexts (most recently Oscar winning Hollywood films). For the past five years Halldór has been at the Design Department of the Icelandic Academy of Art and part time lecturing in the Music Department in the same school. He is now pursuing a PhD at the Music Department at University of Sussex with Drs. Thor Magnusson and Chris Kiefer.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/violbulge.jpg&quot; alt=&quot;Violin&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;b&gt;Iain Emsley&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Title: &lt;b&gt;To sonify, or not to sonify&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;In between other projects, I experiment with sonification as a critical tool. In this presentation, I show some of my work with extracting parts of editorial structures of Shakespeare’s Hamlet, explore a software community, and traffic changes in national network. I present some of the models and the questions that were raised as ongoing work.&lt;/p&gt;

&lt;p&gt;Bio: Iain works a Research Associate at the Oxford e-Research Centre on digital libraries, software sustainability, and user interfaces for the museum visitors with visual impairments. Previous roles include working with the Square Kilometre Array, Janet and Forbidden Planet. He is studying for a PhD in Digital Media with Prof David Berry and Thor Magnusson.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/emsley.png&quot; alt=&quot;Emsley&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 24 Oct 2017 00:00:00 +0100</pubDate>
        <link>http://localhost:4000/blog/twophds</link>
        <guid isPermaLink="true">http://localhost:4000/blog/twophds</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>PhD</category>
        
        <category>NIME</category>
        
        <category>sonificiaton</category>
        
        <category>instruments</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Visiting Researcher: Alberto Novello</title>
        <description>&lt;p&gt;&lt;b&gt;:::: Thursday, October 26th, 1.00pm @ SHL ::::&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Our visiting researcher, Dr Alberto Novello, will give a talk at the Sussex Humanities Lab, followed by a short workshop. All welcome!&lt;/p&gt;

&lt;p&gt;Talk Title: &lt;b&gt;Invisible to visible: bio signals and possible applications in the arts.&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;In the lecture I will present my body of work, with a particular emphasis on the bio data installations and performances. I will talk about aesthetics of bio signal performances and the correlated dramaturgical limitations. I will explain the approach I followed when creating Fragmentation, UN (focussed) and Brain Pong: my three works using EEG signals. I will explain the techniques and mathematical tools I used and discuss/criticize the final results.&lt;/p&gt;

&lt;p&gt;After the lecture there will be a &lt;b&gt;workshop&lt;/b&gt; on the same topic, open to all:&lt;/p&gt;

&lt;p&gt;The focus of the workshop is to get first acquainted with the hardware: two EEG headsets will be compared in their level of complexity to setup vs quality of their data. The workshop will also talk about the possible alternatives on the market the pros and cons of the most common headsets around. The second part of the workshop will focus on software and data analysis: what kind of high-level features can we extract from the raw EEG data? How should we treat that data to extract for example energy bands? What do those band mean and how do they correlate with our everyday brain activity? In the third part, the participants will be encouraged to imagine a possible short performance/installation and, in groups, try and sketch a possible code for it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/novello.jpg&quot; alt=&quot;Novello&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Alberto Novello is a scientist, composer, sound and video artist. His main artistic focus is directed towards the creation of probabilistic multi-media architectures, on the technological limit between instability and error, failure and expression. Lately he moved from digital systems to analog found or decontextualized electronic ensembles.&lt;/p&gt;

&lt;p&gt;He graduated in Nuclear Physics at the University of Trieste, completed the master “Art, Science and Technologies” with Jean Claude Risset and Claude Cadoz, he obtained a PhD degree at the Technische Universiteit Eindhoven with Armin Kohlrausch and graduated in electroacoustic music composition at the Institute of Sonology, Royal Conservatory of Den Haag with Paul Berg, Joel Ryan, and Richard Barret. In his works, he has assisted Alvin Lucier, Nicholas Collins and Trevor Wishart. In the years he also worked Philips Research, Eindhoven, and Auro Technologies Belgium creating software for their audio application.&lt;/p&gt;

&lt;p&gt;His artistic works have been presented in international festivals such as Amsterdam Dance Event, Venice Biennale, Impuls Tanz Vienna, Seoul International Music Festival, Emu Fest Roma, Monaco Electroacoustique, New York Computer Music Festival, Rewire Festival and conferences such as NIME, ICMC, ISMIR, ICMPC, ICA, ICCE and ESSEM and institutes for contemporary music research such as CCMAS in Mexico, GRM in France, Logos Foundation in Belgium, STEIM Amsterdam, IEM Graz, OMI New York, the Royal Conservatory of Den Haag, Conservatory of Padua.&lt;/p&gt;

&lt;p&gt;He was part of the Sonology Electroacoustic Ensemble. He has released his works on CD/DVD as “JesterN’ for Dobialabel, Modisti, Bowindo, SONMA Archive and Hybrida records.&lt;/p&gt;

&lt;p&gt;Novello has improvised with Evan Parker and Butch Morris, Karl Berger and composed for the choreographies of Ola Maciejewska and Liat Waysbort.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;www.jestern.com&quot;&gt;www.jestern.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ALBERTO NOVELLO / JesterN&lt;br /&gt;
site: &lt;a href=&quot;www.jestern.com&quot;&gt;jestern.com&lt;/a&gt;&lt;br /&gt;
shop: &lt;a href=&quot;www.jestern.bandcamp.com&quot;&gt;jestern.bandcamp.com&lt;/a&gt;&lt;br /&gt;
audio: &lt;a href=&quot;www.soundcloud.com/jestern&quot;&gt;soundcloud.com/jestern&lt;/a&gt;&lt;br /&gt;
video: &lt;a href=&quot;www.vimeo.com/jestern&quot;&gt;vimeo.com/jestern&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 10 Oct 2017 00:00:00 +0100</pubDate>
        <link>http://localhost:4000/blog/novello</link>
        <guid isPermaLink="true">http://localhost:4000/blog/novello</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>machine learning</category>
        
        <category>analog synthesis</category>
        
        <category>brain interfaces</category>
        
        <category>laser</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Residency Report: Marije Baalman and Chrysalis</title>
        <description>&lt;p&gt;For the past six days, &lt;a href=&quot;https://www.marijebaalman.eu&quot;&gt;Marije Baalman&lt;/a&gt; has been visiting Sussex for part one of a residency with by EMuteLab and Sussex Humanities Lab.   We’ve been exploring serendipity in mappings for interactive instruments, and focusing on her recent piece &lt;a href=&quot;https://www.marijebaalman.eu/projects/chrysalis.html&quot;&gt;Chrysalis&lt;a&gt;.&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Chrysalis is a cocoon like instrument made from stretch fabric and poles. You crawl into the structure, and when you move around, the wireless accelerometers and stretch sensors (using Marije’s SenseStage system) are mapped to sound and to RGB lights which light up the chrysalis.  Marije wanted to explore new mappings which were less predictable and more engaging to interact with, while at the same time, did not risk moving into modes that were too random or out of keeping with the broad aesthetics of the piece.  Following from some of my &lt;a href=&quot;https://sro.sussex.ac.uk/51860/1/NIME2014-ESN.pdf&quot;&gt;previous work using Echo State Networks&lt;/a&gt; to create complex mappings, we explored Jaeger’s more recent innovations in this area, using a new technique: &lt;a href=&quot;http://minds.jacobs-university.de/conceptors&quot;&gt;Conceptors&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Conceptors essentially capture modes of behaviour of a reccurrent neural network, after which they can be used for pattern generation and for sequence recognition.  When used for pattern generation, they have some very interesting properties: you can mix and morph between patterns and also extrapolate new pattern variations.  This fitted in really well with our aim of encouraging interesting variation in mappings, while staying within a broader aesthetic.  Conceptors allow the creation of new and interesting pattern variations, but without moving too far from the original pattern. In other words, we can create surprises without the risk of them being too surprising.  The addition bonus is that these patterns are generated in real time, and can interact intuitively with sensors. We mapped them to control lighting patterns, and also used the network activations as wavetables to synthesise sound.&lt;/p&gt;

&lt;p&gt;Another innovation was to adapt conceptors for realtime sequence recognition.  This worked successfully with accelerometer data. The way in which conceptors can be used with boolean logic make them a very powerful tool for pattern classification which we will be exploring more before Marije returns for part 2 of her residency in January.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/chrysalis2.jpg&quot; alt=&quot;Chrsalis&quot; /&gt;
&lt;img src=&quot;/img/chrysalis3.jpg&quot; alt=&quot;Chrsalis&quot; /&gt;
&lt;img src=&quot;/img/chrysalis_shl_lightson.jpg&quot; alt=&quot;Chrsalis&quot; /&gt;
&lt;img src=&quot;/img/chrysalis-diag.jpg&quot; alt=&quot;Chrsalis&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 14 Sep 2017 00:00:00 +0100</pubDate>
        <link>http://localhost:4000/blog/chrysalis-report</link>
        <guid isPermaLink="true">http://localhost:4000/blog/chrysalis-report</guid>
        
        <category>emutelab</category>
        
        <category>event</category>
        
        <category>machine learning</category>
        
        <category>live coding</category>
        
        
        <category>blog</category>
        
      </item>
    
  </channel>
</rss>
